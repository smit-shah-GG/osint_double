---
phase: 07-fact-classification-system
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - osint_system/agents/sifters/credibility/__init__.py
  - osint_system/agents/sifters/credibility/source_scorer.py
  - osint_system/agents/sifters/credibility/echo_detector.py
  - osint_system/agents/sifters/fact_classification_agent.py
  - osint_system/config/source_credibility.py
  - tests/agents/sifters/credibility/test_source_scorer.py
  - tests/agents/sifters/credibility/test_echo_detector.py
autonomous: true

must_haves:
  truths:
    - "Credibility formula computes Claim Score = Sigma(SourceCred x Proximity x Precision)"
    - "Proximity uses exponential decay: 0.7^hop_count"
    - "Echo detection uses logarithmic dampening: alpha * log10(1 + sum_echoes)"
    - "Source credibility has pre-configured baselines for known sources"
    - "Unknown sources start from scratch with type-based defaults"
    - "Single-source limitation: Full multi-source echo dampening requires Phase 8 variant provenance enrichment; this plan scores primary source only"
  artifacts:
    - path: "osint_system/agents/sifters/credibility/source_scorer.py"
      provides: "SourceCredibilityScorer with multi-factor credibility computation"
      exports: ["SourceCredibilityScorer"]
      min_lines: 180
    - path: "osint_system/agents/sifters/credibility/echo_detector.py"
      provides: "EchoDetector for root source diversity and circular reporting detection"
      exports: ["EchoDetector", "EchoScore"]
      min_lines: 150
    - path: "osint_system/config/source_credibility.py"
      provides: "Pre-configured source baselines and type defaults"
      exports: ["SOURCE_BASELINES", "SOURCE_TYPE_DEFAULTS", "PROXIMITY_DECAY_FACTOR"]
      min_lines: 80
  key_links:
    - from: "osint_system/agents/sifters/fact_classification_agent.py"
      to: "osint_system/agents/sifters/credibility/source_scorer.py"
      via: "SourceCredibilityScorer for _compute_credibility"
      pattern: "from.*credibility.*import.*SourceCredibilityScorer"
    - from: "osint_system/agents/sifters/credibility/source_scorer.py"
      to: "osint_system/agents/sifters/credibility/echo_detector.py"
      via: "EchoDetector for circular reporting check"
      pattern: "from.*echo_detector.*import.*EchoDetector"
    - from: "osint_system/agents/sifters/credibility/source_scorer.py"
      to: "osint_system/config/source_credibility.py"
      via: "Source baselines configuration"
      pattern: "from.*source_credibility.*import"
---

<objective>
Implement the credibility scoring system per Phase 7 CONTEXT.md formula.

Purpose: Credibility scores are the foundation for classification. The formula prevents gaming via logarithmic echo dampening and uses exponential proximity decay. Pre-configured baselines for known sources (Reuters, AP) with type-based defaults for unknown sources.

Output: Complete credibility scoring pipeline integrated into FactClassificationAgent._compute_credibility().
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-fact-classification-system/07-CONTEXT.md
@.planning/phases/07-fact-classification-system/07-01-SUMMARY.md

# Schemas we need
@osint_system/data_management/schemas/fact_schema.py
@osint_system/data_management/schemas/provenance_schema.py
@osint_system/data_management/schemas/classification_schema.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create source credibility configuration</name>
  <files>osint_system/config/source_credibility.py</files>
  <action>
Create configuration for source credibility baselines and type defaults.

**source_credibility.py:**
```python
"""Source credibility configuration for fact classification.

Per Phase 7 CONTEXT.md:
- Pre-configured baselines for known sources (hybrid approach)
- Type-based defaults for unknown sources
- Proximity decay factor for hop count

Source hierarchy (from most to least credible):
1. Wire services (Reuters, AP, AFP): 0.9
2. Official government sources (.gov): 0.85
3. Educational/research (.edu): 0.85
4. Major news outlets (BBC, NYT): 0.8
5. Regional/specialty news: 0.7
6. Non-profit organizations (.org): 0.7
7. Social media: 0.3
8. Anonymous/unknown: 0.2
"""

from typing import Dict

# Pre-configured baselines for known sources
# Key: domain or source identifier (lowercase)
# Value: credibility score 0.0-1.0
SOURCE_BASELINES: Dict[str, float] = {
    # Wire services (highest credibility)
    "reuters.com": 0.9,
    "apnews.com": 0.9,
    "afp.com": 0.9,
    "tass.com": 0.75,  # State-affiliated, lower than independent
    "xinhua.net": 0.7,  # State-affiliated

    # Major news outlets
    "bbc.com": 0.85,
    "bbc.co.uk": 0.85,
    "nytimes.com": 0.85,
    "washingtonpost.com": 0.85,
    "theguardian.com": 0.82,
    "economist.com": 0.85,
    "ft.com": 0.85,  # Financial Times
    "wsj.com": 0.85,  # Wall Street Journal
    "cnn.com": 0.75,
    "foxnews.com": 0.7,
    "aljazeera.com": 0.75,

    # Government sources (domain patterns handled separately)
    # These are defaults - specific .gov domains may override

    # Research/academic
    # .edu domains handled by type default

    # Known lower-credibility sources
    "rt.com": 0.4,  # State-controlled propaganda
    "sputniknews.com": 0.4,  # State-controlled propaganda
    "breitbart.com": 0.5,  # High bias
    "infowars.com": 0.2,  # Conspiracy/misinformation

    # Social media platforms (user-generated content)
    "twitter.com": 0.3,
    "x.com": 0.3,
    "reddit.com": 0.3,
    "facebook.com": 0.3,
    "telegram.org": 0.3,
}

# Type-based defaults for unknown sources
# Used when source not in SOURCE_BASELINES
SOURCE_TYPE_DEFAULTS: Dict[str, float] = {
    "wire_service": 0.85,
    "official_statement": 0.8,  # Government press releases
    "news_outlet": 0.6,  # Unknown news outlet
    "social_media": 0.3,
    "academic": 0.85,
    "document": 0.5,  # Leaked/unofficial documents
    "eyewitness": 0.6,  # Direct observation (varies widely)
    "unknown": 0.3,
}

# Domain pattern defaults (for TLD-based scoring)
DOMAIN_PATTERN_DEFAULTS: Dict[str, float] = {
    ".gov": 0.85,  # Government domains
    ".mil": 0.85,  # Military domains
    ".edu": 0.85,  # Educational institutions
    ".org": 0.7,   # Non-profit organizations
    ".int": 0.85,  # International organizations
}

# Proximity decay factor
# Per CONTEXT.md: 0.7^hop (moderate decay, secondary sources still meaningful)
# hop_count=0: 1.0, hop_count=1: 0.7, hop_count=2: 0.49, hop_count=3: 0.343
PROXIMITY_DECAY_FACTOR: float = 0.7

# Echo dampening factor (alpha)
# Per CONTEXT.md: α ≈ 0.2
ECHO_DAMPENING_ALPHA: float = 0.2

# Precision scoring weights
PRECISION_WEIGHTS: Dict[str, float] = {
    "entity_count": 0.3,      # More entities = more precise
    "temporal_precision": 0.3, # Explicit dates = more precise
    "has_quote": 0.2,         # Direct quotes = more verifiable
    "has_document": 0.2,      # Document citation = more verifiable
}

# Entity significance scores (for impact assessment in Plan 03)
ENTITY_SIGNIFICANCE: Dict[str, float] = {
    "world_leader": 1.0,      # Presidents, prime ministers
    "senior_official": 0.8,   # Cabinet members, ambassadors
    "military_commander": 0.8,
    "government_official": 0.6,
    "company_executive": 0.5,
    "public_figure": 0.4,
    "organization": 0.4,
    "location_major": 0.6,    # Capitals, major cities
    "location_minor": 0.3,
    "unknown": 0.3,
}

# Event type significance (for impact assessment in Plan 03)
EVENT_TYPE_SIGNIFICANCE: Dict[str, float] = {
    "military_action": 1.0,
    "treaty_agreement": 0.9,
    "sanctions": 0.9,
    "diplomatic_meeting": 0.7,
    "policy_announcement": 0.6,
    "official_statement": 0.5,
    "routine_activity": 0.2,
    "unknown": 0.3,
}
```
  </action>
  <verify>
```bash
uv run python -c "
from osint_system.config.source_credibility import (
    SOURCE_BASELINES, SOURCE_TYPE_DEFAULTS, DOMAIN_PATTERN_DEFAULTS,
    PROXIMITY_DECAY_FACTOR, ECHO_DAMPENING_ALPHA, PRECISION_WEIGHTS
)

print(f'Known sources: {len(SOURCE_BASELINES)}')
print(f'Reuters baseline: {SOURCE_BASELINES.get(\"reuters.com\")}')
print(f'Type defaults: {SOURCE_TYPE_DEFAULTS}')
print(f'Proximity decay: {PROXIMITY_DECAY_FACTOR}')
print(f'Echo alpha: {ECHO_DAMPENING_ALPHA}')
print('Source credibility config OK')
"
```
  </verify>
  <done>Source credibility baselines and configuration established</done>
</task>

<task type="auto">
  <name>Task 2: Implement SourceCredibilityScorer</name>
  <files>
    osint_system/agents/sifters/credibility/__init__.py
    osint_system/agents/sifters/credibility/source_scorer.py
  </files>
  <action>
Create the source credibility scorer implementing the CONTEXT.md formula.

**source_scorer.py:**
```python
"""Source credibility scoring per Phase 7 CONTEXT.md formula.

Core formula: Claim Score = Σ(SourceCred × Proximity × Precision)

Components:
- SourceCred: Source credibility (pre-configured baselines + type defaults)
- Proximity: Exponential decay with hop_count (0.7^hop)
- Precision: Entity count + temporal precision + verifiability signals

This module provides the building blocks. EchoDetector handles
the logarithmic dampening for circular reporting.
"""

import math
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

from loguru import logger

from osint_system.config.source_credibility import (
    DOMAIN_PATTERN_DEFAULTS,
    PRECISION_WEIGHTS,
    PROXIMITY_DECAY_FACTOR,
    SOURCE_BASELINES,
    SOURCE_TYPE_DEFAULTS,
)
from osint_system.data_management.schemas import CredibilityBreakdown


@dataclass
class SourceScore:
    """Score components for a single source."""
    source_id: str
    source_cred: float
    proximity: float
    precision: float
    combined: float  # source_cred * proximity * precision
    is_root: bool = False
    details: Dict[str, Any] = field(default_factory=dict)


class SourceCredibilityScorer:
    """
    Computes source credibility scores for facts.

    Per CONTEXT.md:
    - Pre-configured baselines for known sources
    - Type-based defaults for unknown sources
    - Exponential proximity decay (0.7^hop)
    - Precision from entity count, temporal, verifiability

    Usage:
        scorer = SourceCredibilityScorer()
        score, breakdown = scorer.compute_credibility(fact)
    """

    def __init__(
        self,
        baselines: Optional[Dict[str, float]] = None,
        type_defaults: Optional[Dict[str, float]] = None,
        proximity_decay: float = PROXIMITY_DECAY_FACTOR,
    ):
        """
        Initialize scorer with credibility baselines.

        Args:
            baselines: Custom source baselines (uses defaults if None)
            type_defaults: Custom type defaults (uses defaults if None)
            proximity_decay: Decay factor per hop (default 0.7)
        """
        self.baselines = baselines or SOURCE_BASELINES
        self.type_defaults = type_defaults or SOURCE_TYPE_DEFAULTS
        self.proximity_decay = proximity_decay
        self.logger = logger.bind(component="SourceCredibilityScorer")

    def compute_credibility(
        self,
        fact: Dict[str, Any],
    ) -> tuple[float, CredibilityBreakdown]:
        """
        Compute credibility score for a fact.

        Per CONTEXT.md formula:
        - For single source: SourceCred × Proximity × Precision
        - For multiple sources: Handled by EchoDetector (Plan 03)

        Args:
            fact: ExtractedFact dict with provenance

        Returns:
            (credibility_score, breakdown)
        """
        provenance = fact.get("provenance")
        if not provenance:
            # No provenance = unknown credibility
            return 0.3, self._empty_breakdown()

        # Score the primary source
        source_score = self._score_source(fact, provenance)

        # Build breakdown
        breakdown = CredibilityBreakdown(
            s_root=source_score.source_cred,
            s_echoes_sum=0.0,  # Single source, no echoes
            proximity_scores=[source_score.proximity],
            precision_scores=[source_score.precision],
            echo_bonus=0.0,
        )

        credibility = source_score.combined
        self.logger.debug(
            f"Credibility computed: {credibility:.3f}",
            source=source_score.source_id[:50],
            components=source_score.details,
        )

        return credibility, breakdown

    def _score_source(
        self,
        fact: Dict[str, Any],
        provenance: Dict[str, Any],
    ) -> SourceScore:
        """
        Score a single source.

        Args:
            fact: ExtractedFact dict
            provenance: Provenance dict from fact

        Returns:
            SourceScore with all components
        """
        source_id = provenance.get("source_id", "unknown")

        # 1. Source credibility
        source_cred = self._get_source_credibility(
            source_id,
            provenance.get("source_type", "unknown"),
        )

        # 2. Proximity (exponential decay with hop count)
        hop_count = provenance.get("hop_count", 1)
        proximity = self._compute_proximity(hop_count)

        # 3. Precision
        precision = self._compute_precision(fact, provenance)

        # Combined score
        combined = source_cred * proximity * precision

        return SourceScore(
            source_id=source_id,
            source_cred=source_cred,
            proximity=proximity,
            precision=precision,
            combined=combined,
            is_root=(hop_count == 0),
            details={
                "hop_count": hop_count,
                "source_type": provenance.get("source_type"),
                "baseline_used": self._find_baseline_key(source_id),
            },
        )

    def _get_source_credibility(
        self,
        source_id: str,
        source_type: str,
    ) -> float:
        """
        Get credibility score for a source.

        Priority:
        1. Exact match in baselines
        2. Domain extraction and baseline lookup
        3. Domain pattern match (.gov, .edu, etc.)
        4. Type-based default
        5. Fallback to 0.3

        Args:
            source_id: Source identifier (often URL)
            source_type: Source type from provenance

        Returns:
            Credibility score 0.0-1.0
        """
        # Try exact match
        source_lower = source_id.lower()
        if source_lower in self.baselines:
            return self.baselines[source_lower]

        # Extract domain from URL
        domain = self._extract_domain(source_id)
        if domain and domain in self.baselines:
            return self.baselines[domain]

        # Try domain patterns
        if domain:
            for pattern, score in DOMAIN_PATTERN_DEFAULTS.items():
                if domain.endswith(pattern):
                    return score

        # Type-based default
        source_type_lower = source_type.lower() if source_type else "unknown"
        return self.type_defaults.get(source_type_lower, 0.3)

    def _extract_domain(self, source_id: str) -> Optional[str]:
        """Extract domain from URL or source identifier."""
        if not source_id:
            return None

        try:
            # Try as URL
            parsed = urlparse(source_id)
            if parsed.netloc:
                domain = parsed.netloc.lower()
                # Remove www. prefix
                if domain.startswith("www."):
                    domain = domain[4:]
                return domain

            # Not a URL, might be a domain directly
            if "." in source_id and "/" not in source_id:
                return source_id.lower()

        except Exception:
            pass

        return None

    def _find_baseline_key(self, source_id: str) -> Optional[str]:
        """Find which baseline key was used (for debugging)."""
        source_lower = source_id.lower()
        if source_lower in self.baselines:
            return source_lower

        domain = self._extract_domain(source_id)
        if domain and domain in self.baselines:
            return domain

        return None

    def _compute_proximity(self, hop_count: int) -> float:
        """
        Compute proximity score with exponential decay.

        Per CONTEXT.md: 0.7^hop (moderate decay)
        - hop=0: 1.0 (eyewitness)
        - hop=1: 0.7
        - hop=2: 0.49
        - hop=3: 0.343

        Args:
            hop_count: Number of hops from original source

        Returns:
            Proximity score 0.0-1.0
        """
        return self.proximity_decay ** hop_count

    def _compute_precision(
        self,
        fact: Dict[str, Any],
        provenance: Dict[str, Any],
    ) -> float:
        """
        Compute precision score from verifiability signals.

        Per CONTEXT.md components:
        - Entity count (more named entities = more precise)
        - Temporal precision (explicit dates = more precise)
        - Has quote (direct quotes = more verifiable)
        - Has document citation (more verifiable)

        Args:
            fact: ExtractedFact dict
            provenance: Provenance dict

        Returns:
            Precision score 0.0-1.0
        """
        scores = {}

        # Entity count factor (0-1, scales with entities)
        entities = fact.get("entities", [])
        entity_count = len(entities)
        # Diminishing returns: 1 entity = 0.5, 3+ = 1.0
        entity_factor = min(1.0, 0.3 + (entity_count * 0.233))
        scores["entity_count"] = entity_factor * PRECISION_WEIGHTS.get("entity_count", 0.25)

        # Temporal precision factor
        temporal = fact.get("temporal")
        if temporal:
            temporal_precision = temporal.get("temporal_precision", "unknown")
            if temporal_precision == "explicit":
                temporal_factor = 1.0
            elif temporal_precision == "inferred":
                temporal_factor = 0.6
            else:
                temporal_factor = 0.3
        else:
            temporal_factor = 0.3  # No temporal info
        scores["temporal_precision"] = temporal_factor * PRECISION_WEIGHTS.get("temporal_precision", 0.25)

        # Quote factor
        quote = provenance.get("quote", "")
        attribution_phrase = provenance.get("attribution_phrase", "")
        has_direct_quote = quote and (
            '"' in quote or "'" in quote or
            "said" in attribution_phrase.lower()
        )
        quote_factor = 1.0 if has_direct_quote else 0.5
        scores["has_quote"] = quote_factor * PRECISION_WEIGHTS.get("has_quote", 0.25)

        # Document citation factor
        attribution_chain = provenance.get("attribution_chain", [])
        has_document = any(
            hop.get("type") in ("document", "official_statement", "academic")
            for hop in attribution_chain
        )
        doc_factor = 1.0 if has_document else 0.5
        scores["has_document"] = doc_factor * PRECISION_WEIGHTS.get("has_document", 0.25)

        # Total precision (weighted sum, normalized to 0-1)
        total = sum(scores.values())
        # Ensure we're in 0-1 range (weights should sum to 1.0)
        precision = min(1.0, total)

        return precision

    def _empty_breakdown(self) -> CredibilityBreakdown:
        """Create empty breakdown for missing provenance."""
        return CredibilityBreakdown(
            s_root=0.3,
            s_echoes_sum=0.0,
            proximity_scores=[],
            precision_scores=[],
            echo_bonus=0.0,
        )

    def score_multiple_sources(
        self,
        fact: Dict[str, Any],
        additional_provenances: List[Dict[str, Any]],
    ) -> tuple[float, CredibilityBreakdown, List[SourceScore]]:
        """
        Score a fact with multiple sources (for consolidation).

        Used by EchoDetector to handle multiple sources reporting same claim.
        The primary source becomes the root; additional sources become echoes.

        Args:
            fact: ExtractedFact dict (primary provenance)
            additional_provenances: List of additional provenance dicts

        Returns:
            (credibility_score, breakdown, source_scores)
        """
        # Score primary source
        primary_provenance = fact.get("provenance", {})
        source_scores = []

        if primary_provenance:
            primary_score = self._score_source(fact, primary_provenance)
            primary_score.is_root = True
            source_scores.append(primary_score)

        # Score additional sources
        for prov in additional_provenances:
            # Create minimal fact dict for scoring
            minimal_fact = {
                "entities": fact.get("entities", []),
                "temporal": fact.get("temporal"),
            }
            score = self._score_source(minimal_fact, prov)
            source_scores.append(score)

        if not source_scores:
            return 0.3, self._empty_breakdown(), []

        # Root is highest credibility source
        source_scores.sort(key=lambda s: s.combined, reverse=True)
        root = source_scores[0]
        root.is_root = True
        echoes = source_scores[1:]

        # Build breakdown
        breakdown = CredibilityBreakdown(
            s_root=root.source_cred,
            s_echoes_sum=sum(s.combined for s in echoes),
            proximity_scores=[s.proximity for s in source_scores],
            precision_scores=[s.precision for s in source_scores],
            echo_bonus=0.0,  # Calculated by EchoDetector
        )

        # Credibility is root score (echo bonus added by EchoDetector)
        return root.combined, breakdown, source_scores


# Package init
__all__ = ["SourceCredibilityScorer", "SourceScore"]
```

**__init__.py:**
```python
"""Credibility scoring components for fact classification."""

from osint_system.agents.sifters.credibility.source_scorer import (
    SourceCredibilityScorer,
    SourceScore,
)

__all__ = [
    "SourceCredibilityScorer",
    "SourceScore",
]
```
  </action>
  <verify>
```bash
uv run python -c "
from osint_system.agents.sifters.credibility import SourceCredibilityScorer

scorer = SourceCredibilityScorer()

# Test with Reuters source
fact = {
    'fact_id': 'test-1',
    'claim': {'text': 'Test claim'},
    'entities': [{'id': 'E1', 'text': 'Putin', 'type': 'PERSON'}],
    'temporal': {'id': 'T1', 'value': '2024-03', 'precision': 'month', 'temporal_precision': 'explicit'},
    'provenance': {
        'source_id': 'https://reuters.com/article/123',
        'source_type': 'wire_service',
        'hop_count': 1,
        'quote': 'Putin visited Beijing',
        'attribution_phrase': 'according to Reuters',
        'offsets': {'start': 0, 'end': 100}
    }
}

score, breakdown = scorer.compute_credibility(fact)
print(f'Reuters credibility: {score:.3f}')
print(f'  Root cred: {breakdown.s_root:.2f}')
print(f'  Proximity: {breakdown.proximity_scores}')
print(f'  Precision: {breakdown.precision_scores}')

# Test with unknown source
fact2 = {
    'fact_id': 'test-2',
    'claim': {'text': 'Test claim'},
    'provenance': {
        'source_id': 'random-blog.com',
        'source_type': 'unknown',
        'hop_count': 3,
        'offsets': {'start': 0, 'end': 50}
    }
}

score2, _ = scorer.compute_credibility(fact2)
print(f'Unknown source credibility: {score2:.3f}')

assert score > score2, 'Reuters should be more credible than unknown'
print('SourceCredibilityScorer OK')
"
```
  </verify>
  <done>SourceCredibilityScorer with baseline lookups and formula computation</done>
</task>

<task type="auto">
  <name>Task 3: Implement EchoDetector</name>
  <files>osint_system/agents/sifters/credibility/echo_detector.py</files>
  <action>
Create echo detector for circular reporting detection and logarithmic dampening.

**echo_detector.py:**
```python
"""Echo detection for circular reporting and source diversity.

Per Phase 7 CONTEXT.md:
Root Source Diversity (anti-circular-reporting):
- Detect shared roots via explicit attribution tracking (provenance chain from Phase 6)
- Use logarithmic decay for echo scoring:
  Total Score = S_root + (alpha * log10(1 + sum(S_echoes)))

The logarithmic formula prevents gaming:
- Fact A (Reuters only): Score 0.9
- Fact B (Reuters + 3 Major Papers): Score ~1.1 (verified by editorial review)
- Fact C (Reuters + 10,000 Twitter Bots): Score ~1.15 (effectively capped)

1M low-quality bots get crushed by the log function.
"""

import math
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Set

from loguru import logger

from osint_system.config.source_credibility import ECHO_DAMPENING_ALPHA
from osint_system.data_management.schemas import CredibilityBreakdown


@dataclass
class EchoCluster:
    """A cluster of sources sharing the same root."""
    root_entity: str
    root_hop: int
    sources: List[str] = field(default_factory=list)
    combined_score: float = 0.0


@dataclass
class EchoScore:
    """Result of echo analysis."""
    root_score: float           # S_root: highest quality source
    echo_sum: float             # Σ S_echoes
    echo_bonus: float           # α · log₁₀(1 + Σ S_echoes)
    total_score: float          # S_root + echo_bonus
    unique_roots: int           # Number of independent root sources
    echo_clusters: List[EchoCluster] = field(default_factory=list)
    circular_warning: bool = False  # True if circular reporting detected


class EchoDetector:
    """
    Detects echo chambers and computes logarithmic dampening.

    Per CONTEXT.md:
    - Detect shared roots via attribution chain analysis
    - Apply logarithmic dampening to prevent gaming
    - First quality echo adds value, 100th adds near-zero

    Usage:
        detector = EchoDetector()
        echo_score = detector.analyze_sources(source_scores)
        breakdown.echo_bonus = echo_score.echo_bonus
    """

    def __init__(self, alpha: float = ECHO_DAMPENING_ALPHA):
        """
        Initialize echo detector.

        Args:
            alpha: Dampening factor for echo contribution (default 0.2)
        """
        self.alpha = alpha
        self.logger = logger.bind(component="EchoDetector")

    def analyze_sources(
        self,
        provenances: List[Dict[str, Any]],
        source_scores: Optional[List[float]] = None,
    ) -> EchoScore:
        """
        Analyze multiple sources for echoes and compute dampened score.

        Args:
            provenances: List of provenance dicts from variants/corroborating facts
            source_scores: Pre-computed credibility scores for each source

        Returns:
            EchoScore with root, echo contribution, and total
        """
        if not provenances:
            return EchoScore(
                root_score=0.0,
                echo_sum=0.0,
                echo_bonus=0.0,
                total_score=0.0,
                unique_roots=0,
            )

        # Default scores if not provided
        if source_scores is None:
            source_scores = [0.5] * len(provenances)

        # Cluster sources by root
        clusters = self._cluster_by_root(provenances, source_scores)

        # Find the highest quality independent root
        root_clusters = [c for c in clusters if c.root_hop == 0 or len(c.sources) == 1]
        if root_clusters:
            root_cluster = max(root_clusters, key=lambda c: c.combined_score)
            root_score = root_cluster.combined_score
        else:
            # No clear root, use highest scoring source
            root_score = max(source_scores) if source_scores else 0.0

        # Compute echo sum (all sources except the root)
        echo_sum = sum(source_scores) - root_score

        # Apply logarithmic dampening
        echo_bonus = self._compute_echo_bonus(echo_sum)

        # Total score
        total_score = root_score + echo_bonus

        # Detect circular reporting
        circular_warning = self._detect_circular_reporting(clusters, provenances)

        unique_roots = len([c for c in clusters if c.root_hop == 0])

        result = EchoScore(
            root_score=root_score,
            echo_sum=echo_sum,
            echo_bonus=echo_bonus,
            total_score=total_score,
            unique_roots=unique_roots,
            echo_clusters=clusters,
            circular_warning=circular_warning,
        )

        self.logger.debug(
            f"Echo analysis: root={root_score:.2f}, echo_bonus={echo_bonus:.3f}, total={total_score:.2f}",
            unique_roots=unique_roots,
            circular=circular_warning,
        )

        return result

    def _cluster_by_root(
        self,
        provenances: List[Dict[str, Any]],
        source_scores: List[float],
    ) -> List[EchoCluster]:
        """
        Cluster sources by their ultimate root in attribution chain.

        Sources citing the same original entity are clustered together.
        """
        clusters: Dict[str, EchoCluster] = {}

        for prov, score in zip(provenances, source_scores):
            # Find root entity from attribution chain
            root_entity, root_hop = self._find_root(prov)

            if root_entity not in clusters:
                clusters[root_entity] = EchoCluster(
                    root_entity=root_entity,
                    root_hop=root_hop,
                )

            clusters[root_entity].sources.append(prov.get("source_id", "unknown"))
            clusters[root_entity].combined_score += score

        return list(clusters.values())

    def _find_root(self, provenance: Dict[str, Any]) -> tuple[str, int]:
        """
        Find the root entity in an attribution chain.

        Returns:
            (root_entity, root_hop): Name of root and its hop level
        """
        attribution_chain = provenance.get("attribution_chain", [])

        if attribution_chain:
            # Find the hop with lowest hop number (closest to origin)
            root_hop = min(attribution_chain, key=lambda h: h.get("hop", 999))
            return root_hop.get("entity", "unknown"), root_hop.get("hop", 0)

        # No chain, use source_id as root
        source_id = provenance.get("source_id", "unknown")
        hop_count = provenance.get("hop_count", 1)
        return source_id, hop_count

    def _compute_echo_bonus(self, echo_sum: float) -> float:
        """
        Compute logarithmic echo bonus.

        Per CONTEXT.md: α · log₁₀(1 + Σ S_echoes)

        This formula:
        - echo_sum=0: bonus=0
        - echo_sum=1: bonus=α·log₁₀(2) ≈ 0.06
        - echo_sum=10: bonus=α·log₁₀(11) ≈ 0.21
        - echo_sum=100: bonus=α·log₁₀(101) ≈ 0.40
        - echo_sum=10000: bonus=α·log₁₀(10001) ≈ 0.80

        Diminishing returns crush botnet spam.
        """
        if echo_sum <= 0:
            return 0.0

        return self.alpha * math.log10(1 + echo_sum)

    def _detect_circular_reporting(
        self,
        clusters: List[EchoCluster],
        provenances: List[Dict[str, Any]],
    ) -> bool:
        """
        Detect potential circular reporting patterns.

        Warnings triggered when:
        - All sources trace back to same root
        - No primary sources (all hop_count > 0)
        - Suspicious cross-citation patterns
        """
        if len(provenances) <= 1:
            return False

        # Check if all cluster to single root
        if len(clusters) == 1 and len(provenances) > 2:
            cluster = clusters[0]
            if cluster.root_hop > 0:
                # All sources trace to non-primary root
                self.logger.warning(
                    f"Potential circular reporting: {len(provenances)} sources, "
                    f"single root at hop {cluster.root_hop}"
                )
                return True

        # Check if no primary sources exist
        has_primary = any(
            p.get("hop_count", 1) == 0 or
            p.get("source_classification") == "primary"
            for p in provenances
        )
        if not has_primary and len(provenances) > 3:
            self.logger.warning(
                f"No primary sources among {len(provenances)} sources"
            )
            return True

        return False

    def update_breakdown(
        self,
        breakdown: CredibilityBreakdown,
        echo_score: EchoScore,
    ) -> CredibilityBreakdown:
        """
        Update credibility breakdown with echo analysis results.

        Args:
            breakdown: Existing breakdown from SourceCredibilityScorer
            echo_score: Result from analyze_sources()

        Returns:
            Updated breakdown with echo_bonus
        """
        breakdown.s_root = echo_score.root_score
        breakdown.s_echoes_sum = echo_score.echo_sum
        breakdown.echo_bonus = echo_score.echo_bonus
        return breakdown

    def compute_corroboration_strength(
        self,
        unique_roots: int,
        root_score: float,
    ) -> float:
        """
        Compute how well a fact is corroborated.

        More independent roots = stronger corroboration.
        Used for impact assessment (well-corroborated critical facts).

        Returns:
            Corroboration strength 0.0-1.0
        """
        if unique_roots <= 1:
            return 0.3  # Single source

        # Diminishing returns for more roots
        root_factor = min(1.0, 0.3 + (unique_roots - 1) * 0.175)
        return root_factor * min(1.0, root_score + 0.2)


# Update package __all__
__all__ = ["EchoDetector", "EchoScore", "EchoCluster"]
```

**Update credibility/__init__.py:**
Add EchoDetector exports.
  </action>
  <verify>
```bash
uv run python -c "
from osint_system.agents.sifters.credibility import EchoDetector, EchoScore

detector = EchoDetector()

# Test with multiple sources
provenances = [
    {
        'source_id': 'reuters.com/article1',
        'hop_count': 1,
        'attribution_chain': [
            {'entity': 'Kremlin spokesperson', 'type': 'official_statement', 'hop': 0},
            {'entity': 'TASS', 'type': 'wire_service', 'hop': 1}
        ]
    },
    {
        'source_id': 'bbc.com/news/123',
        'hop_count': 2,
        'attribution_chain': [
            {'entity': 'Kremlin spokesperson', 'type': 'official_statement', 'hop': 0},
            {'entity': 'TASS', 'type': 'wire_service', 'hop': 1},
            {'entity': 'Reuters', 'type': 'wire_service', 'hop': 2}
        ]
    },
    {
        'source_id': 'nytimes.com/article',
        'hop_count': 2,
        'attribution_chain': [
            {'entity': 'Kremlin spokesperson', 'type': 'official_statement', 'hop': 0},
            {'entity': 'AFP', 'type': 'wire_service', 'hop': 1}
        ]
    }
]

scores = [0.9, 0.8, 0.85]  # Pre-computed source scores

result = detector.analyze_sources(provenances, scores)

print(f'Root score: {result.root_score:.2f}')
print(f'Echo sum: {result.echo_sum:.2f}')
print(f'Echo bonus: {result.echo_bonus:.3f}')
print(f'Total score: {result.total_score:.3f}')
print(f'Unique roots: {result.unique_roots}')
print(f'Circular warning: {result.circular_warning}')

# Test logarithmic dampening
import math
for echo_sum in [0, 1, 10, 100, 1000, 10000]:
    bonus = detector._compute_echo_bonus(echo_sum)
    print(f'  echo_sum={echo_sum}: bonus={bonus:.3f}')

print('EchoDetector OK')
"
```
  </verify>
  <done>EchoDetector with logarithmic dampening and circular reporting detection</done>
</task>

<task type="auto">
  <name>Task 4: Integrate credibility scoring into FactClassificationAgent</name>
  <files>osint_system/agents/sifters/fact_classification_agent.py</files>
  <action>
Update FactClassificationAgent._compute_credibility() to use the scoring system.

**Update fact_classification_agent.py:**

Add imports at top:
```python
from osint_system.agents.sifters.credibility import (
    SourceCredibilityScorer,
    EchoDetector,
)
```

Add lazy initialization properties:
```python
    @property
    def credibility_scorer(self) -> SourceCredibilityScorer:
        """Lazy initialization of credibility scorer."""
        if not hasattr(self, '_credibility_scorer') or self._credibility_scorer is None:
            self._credibility_scorer = SourceCredibilityScorer()
        return self._credibility_scorer

    @property
    def echo_detector(self) -> EchoDetector:
        """Lazy initialization of echo detector."""
        if not hasattr(self, '_echo_detector') or self._echo_detector is None:
            self._echo_detector = EchoDetector()
        return self._echo_detector
```

Replace _compute_credibility() method:
```python
    def _compute_credibility(
        self,
        fact: Dict[str, Any],
    ) -> tuple[float, Optional[CredibilityBreakdown]]:
        """
        Compute credibility score for a fact.

        Per CONTEXT.md formula: Claim Score = Σ(SourceCred × Proximity × Precision)
        Plus logarithmic echo dampening for multiple sources.

        LIMITATION (Phase 7): This plan scores primary source only.
        Full multi-source echo dampening requires Phase 8 variant provenance
        enrichment. The EchoDetector infrastructure is in place, but
        variant provenances are not yet fetched/wired. See Phase 8 for
        complete implementation with variant provenance fetching.

        Args:
            fact: ExtractedFact dict

        Returns:
            (credibility_score, breakdown)
        """
        # Single source scoring (Phase 7 limitation)
        # Phase 8 will add variant provenance fetching for full echo dampening
        score, breakdown = self.credibility_scorer.compute_credibility(fact)

        # Note: EchoDetector is available for Phase 8 integration:
        # variants = fact.get("variants", [])
        # if variants:
        #     variant_provenances = [await fact_store.get_provenance(v) for v in variants]
        #     echo_score = self.echo_detector.analyze_sources(
        #         [fact.get("provenance")] + variant_provenances,
        #         [score] + variant_scores
        #     )
        #     breakdown = self.echo_detector.update_breakdown(breakdown, echo_score)

        return score, breakdown
```
  </action>
  <verify>
```bash
uv run python -c "
import asyncio
from osint_system.agents.sifters import FactClassificationAgent

async def test():
    agent = FactClassificationAgent()

    # Test with fact that has proper provenance
    fact = {
        'fact_id': 'test-f1',
        'claim': {'text': '[E1:Putin] visited [E2:Beijing]'},
        'entities': [
            {'id': 'E1', 'text': 'Putin', 'type': 'PERSON'},
            {'id': 'E2', 'text': 'Beijing', 'type': 'LOCATION'}
        ],
        'temporal': {'id': 'T1', 'value': '2024-03', 'precision': 'month', 'temporal_precision': 'explicit'},
        'quality': {'extraction_confidence': 0.9, 'claim_clarity': 0.8},
        'provenance': {
            'source_id': 'https://reuters.com/article/123',
            'source_type': 'wire_service',
            'hop_count': 1,
            'quote': 'Putin visited Beijing',
            'attribution_phrase': 'according to Reuters citing TASS',
            'offsets': {'start': 0, 'end': 100}
        }
    }

    classifications = await agent.sift({
        'facts': [fact],
        'investigation_id': 'cred-test'
    })

    c = classifications[0]
    print(f'Credibility score: {c[\"credibility_score\"]:.3f}')
    if c.get('credibility_breakdown'):
        b = c['credibility_breakdown']
        print(f'  Root: {b.get(\"s_root\", 0):.2f}')
        print(f'  Proximity: {b.get(\"proximity_scores\", [])}')
        print(f'  Precision: {b.get(\"precision_scores\", [])}')

    assert c['credibility_score'] > 0.5, 'Reuters source should have good credibility'
    print('Credibility integration OK')

asyncio.run(test())
"
```
  </verify>
  <done>FactClassificationAgent uses SourceCredibilityScorer for credibility computation</done>
</task>

<task type="auto">
  <name>Task 5: Add credibility tests</name>
  <files>
    tests/agents/sifters/credibility/__init__.py
    tests/agents/sifters/credibility/test_source_scorer.py
    tests/agents/sifters/credibility/test_echo_detector.py
  </files>
  <action>
Create comprehensive tests for credibility scoring components.

**test_source_scorer.py:**
Test cases:
1. Score known source (Reuters)
2. Score unknown source with type default
3. Domain extraction from URL
4. Domain pattern matching (.gov, .edu)
5. Proximity decay calculation
6. Precision scoring with entities
7. Precision scoring with temporal
8. Multiple source scoring

**test_echo_detector.py:**
Test cases:
1. Single source (no echoes)
2. Multiple independent sources
3. Logarithmic dampening values
4. Circular reporting detection
5. Root clustering by attribution chain
6. Corroboration strength calculation
7. Breakdown update

Create tests/agents/sifters/credibility/__init__.py (empty).
  </action>
  <verify>
```bash
uv run python -m pytest tests/agents/sifters/credibility/ -v
```
  </verify>
  <done>All credibility scoring tests pass</done>
</task>

</tasks>

<verification>
```bash
# All imports work
uv run python -c "
from osint_system.agents.sifters.credibility import SourceCredibilityScorer, EchoDetector
from osint_system.config.source_credibility import SOURCE_BASELINES, PROXIMITY_DECAY_FACTOR
print('All credibility imports OK')
"

# Tests pass
uv run python -m pytest tests/agents/sifters/credibility/ -v

# Integration check: credibility scoring produces expected ranges
uv run python -c "
from osint_system.agents.sifters.credibility import SourceCredibilityScorer

scorer = SourceCredibilityScorer()

# High credibility fact
high = {
    'entities': [{'id': 'E1'}],
    'temporal': {'temporal_precision': 'explicit'},
    'provenance': {
        'source_id': 'https://reuters.com/news',
        'source_type': 'wire_service',
        'hop_count': 0,
        'quote': 'Direct quote from official',
        'attribution_phrase': 'said the official',
        'offsets': {'start': 0, 'end': 50}
    }
}

# Low credibility fact
low = {
    'entities': [],
    'provenance': {
        'source_id': 'random-blog.xyz',
        'source_type': 'unknown',
        'hop_count': 4,
        'offsets': {'start': 0, 'end': 50}
    }
}

high_score, _ = scorer.compute_credibility(high)
low_score, _ = scorer.compute_credibility(low)

print(f'High credibility: {high_score:.3f}')
print(f'Low credibility: {low_score:.3f}')
assert high_score > low_score, 'High should be > Low'
assert high_score > 0.5, 'High should be > 0.5'
assert low_score < 0.3, 'Low should be < 0.3'
print('Credibility ranges OK')
"
```
</verification>

<success_criteria>
- SourceCredibilityScorer computes scores using pre-configured baselines
- Unknown sources fall back to type-based defaults
- Proximity uses exponential decay (0.7^hop)
- Precision incorporates entities, temporal, quotes, documents
- EchoDetector applies logarithmic dampening (alpha * log10(1 + sum))
- Circular reporting detection warns when all sources share root
- FactClassificationAgent._compute_credibility() uses the scoring system
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-fact-classification-system/07-02-SUMMARY.md`
</output>
