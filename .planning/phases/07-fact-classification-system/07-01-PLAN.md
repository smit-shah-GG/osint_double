---
phase: 07-fact-classification-system
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - osint_system/data_management/schemas/classification_schema.py
  - osint_system/data_management/schemas/__init__.py
  - osint_system/data_management/classification_store.py
  - osint_system/agents/sifters/fact_classification_agent.py
  - osint_system/agents/sifters/__init__.py
  - tests/data_management/schemas/test_classification_schema.py
  - tests/agents/sifters/test_fact_classification_agent.py
autonomous: true

must_haves:
  truths:
    - "Classification records are separate from ExtractedFact (facts remain immutable)"
    - "Impact tier (critical/less_critical) and dubious flags are orthogonal dimensions"
    - "Classifications link to facts by fact_id, not by embedding data"
    - "Full audit trail preserves classification history"
    - "Facts can be classified via FactClassificationAgent.sift() returning classification records"
  artifacts:
    - path: "osint_system/data_management/schemas/classification_schema.py"
      provides: "FactClassification Pydantic model with impact tier, dubious flags, audit trail"
      exports: ["FactClassification", "ImpactTier", "DubiousFlag", "CredibilityBreakdown", "ClassificationHistory"]
      min_lines: 150
    - path: "osint_system/data_management/classification_store.py"
      provides: "ClassificationStore for investigation-scoped classification persistence"
      exports: ["ClassificationStore"]
      min_lines: 180
    - path: "osint_system/agents/sifters/fact_classification_agent.py"
      provides: "FactClassificationAgent orchestrating classification pipeline"
      exports: ["FactClassificationAgent"]
      min_lines: 200
  key_links:
    - from: "osint_system/data_management/schemas/classification_schema.py"
      to: "osint_system/data_management/schemas/fact_schema.py"
      via: "fact_id reference, not embedding ExtractedFact"
      pattern: "fact_id.*str"
    - from: "osint_system/agents/sifters/fact_classification_agent.py"
      to: "osint_system/agents/sifters/base_sifter.py"
      via: "BaseSifter inheritance"
      pattern: "class FactClassificationAgent\\(BaseSifter\\)"
    - from: "osint_system/agents/sifters/fact_classification_agent.py"
      to: "osint_system/data_management/classification_store.py"
      via: "ClassificationStore for persistence"
      pattern: "from.*classification_store.*import.*ClassificationStore"
---

<objective>
Define classification schemas and implement FactClassificationAgent with storage.

Purpose: Per Phase 7 CONTEXT.md, classifications are SEPARATE records from facts (facts immutable, classifications mutable). This plan establishes the data model and agent structure. Plans 02 and 03 add the credibility scoring and dubious detection logic.

Output: FactClassification schema, ClassificationStore, and FactClassificationAgent shell ready for scoring/detection logic.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-fact-classification-system/07-CONTEXT.md
@.planning/phases/06-fact-extraction-pipeline/06-01-SUMMARY.md

# Existing patterns
@osint_system/data_management/schemas/fact_schema.py
@osint_system/data_management/fact_store.py
@osint_system/agents/sifters/base_sifter.py
@osint_system/agents/sifters/fact_extraction_agent.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create classification schema</name>
  <files>
    osint_system/data_management/schemas/classification_schema.py
    osint_system/data_management/schemas/__init__.py
  </files>
  <action>
Create Pydantic models for fact classification per 07-CONTEXT.md.

**classification_schema.py:**
```python
"""Classification schema for extracted facts.

Per Phase 7 CONTEXT.md: Classifications are SEPARATE records from facts.
- Facts remain immutable (extraction output)
- Classifications are mutable (update as new information arrives)
- Links fact_id to classification data

Design principle: Detail over compactness. Full audit trails enable:
- Debugging classification logic
- Tracking how classifications evolve
- Understanding WHY something is dubious (not just that it is)
"""

from datetime import datetime, timezone
from enum import Enum
from typing import Literal, Optional

from pydantic import BaseModel, Field


class ImpactTier(str, Enum):
    """Impact tier for facts.

    Per CONTEXT.md: Based on geopolitical significance, NOT relevance to objective.
    Both entity significance AND event type contribute.
    Investigation-relative: same fact may be critical in one investigation, less-critical in another.
    """
    CRITICAL = "critical"
    LESS_CRITICAL = "less_critical"


class DubiousFlag(str, Enum):
    """Taxonomy of doubt - species of dubious classification.

    Per CONTEXT.md: Each species triggers a specific Phase 8 subroutine.
    Flags are independent - a fact can have multiple flags.

    PHANTOM: Structural failure - echo without speaker (hop_count > 2 AND no primary)
    FOG: Attribution failure - vague attribution ("sources say", claim_clarity < 0.5)
    ANOMALY: Coherence failure - contradictions between trusted sources
    NOISE: Reputation failure - source_credibility < 0.3 (batch analysis only)
    """
    PHANTOM = "phantom"  # Structural failure: echo without traceable root
    FOG = "fog"          # Attribution failure: vague/unclear attribution
    ANOMALY = "anomaly"  # Coherence failure: contradictions detected
    NOISE = "noise"      # Reputation failure: known unreliable source


class CredibilityBreakdown(BaseModel):
    """Full credibility score breakdown for debugging and evolution.

    Per CONTEXT.md formula: Claim Score = Σ(SourceCred × Proximity × Precision)
    Plus logarithmic echo dampening: Total = S_root + (α · log₁₀(1 + Σ S_echoes))

    Storing components enables:
    - Formula debugging
    - Score evolution without re-computation
    - Understanding WHY a fact has its score
    """
    s_root: float = Field(0.0, ge=0.0, le=1.0, description="Root source credibility")
    s_echoes_sum: float = Field(0.0, ge=0.0, description="Sum of echo source credibilities")
    proximity_scores: list[float] = Field(
        default_factory=list,
        description="Proximity scores per source (0.7^hop)"
    )
    precision_scores: list[float] = Field(
        default_factory=list,
        description="Precision scores per source"
    )
    echo_bonus: float = Field(
        0.0, ge=0.0,
        description="Logarithmic contribution from echoes: α · log₁₀(1 + Σ S_echoes)"
    )
    alpha: float = Field(0.2, description="Echo dampening factor")

    def compute_total(self) -> float:
        """Compute total score from components."""
        import math
        return self.s_root + (self.alpha * math.log10(1 + self.s_echoes_sum))


class ClassificationReasoning(BaseModel):
    """Reasoning for each dubious flag.

    Per CONTEXT.md: Phase 8 needs to know WHY something is dubious
    to select the appropriate verification subroutine.
    """
    flag: DubiousFlag
    reason: str = Field(..., description="Human-readable explanation")
    trigger_values: dict = Field(
        default_factory=dict,
        description="Values that triggered this flag"
    )

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "flag": "phantom",
                    "reason": "hop_count=4, no primary_source found",
                    "trigger_values": {"hop_count": 4, "primary_source": None}
                },
                {
                    "flag": "fog",
                    "reason": "attribution contains 'reportedly'",
                    "trigger_values": {"attribution_phrase": "reportedly", "claim_clarity": 0.4}
                }
            ]
        }
    }


class ClassificationHistory(BaseModel):
    """Single history entry for classification audit trail.

    Per CONTEXT.md: Full audit trail, not just current state.
    """
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    previous_impact_tier: Optional[ImpactTier] = None
    previous_dubious_flags: list[DubiousFlag] = Field(default_factory=list)
    previous_credibility_score: Optional[float] = None
    trigger: str = Field(..., description="What caused this re-classification")


class FactClassification(BaseModel):
    """Complete classification record for a fact.

    Per CONTEXT.md: Separate from ExtractedFact to allow:
    - Immutable facts with mutable classifications
    - Dynamic re-classification as new information arrives
    - Full audit trails

    Indexing considerations for Phase 8:
    - Priority queue (ordered by priority_score) for general processing
    - Flag-type indexes (all Phantoms, all Fogs, etc.) for specialized subroutines

    Usage:
        classification = FactClassification(
            fact_id="uuid-here",
            investigation_id="inv-123",
            impact_tier=ImpactTier.CRITICAL,
            credibility_score=0.85
        )
    """
    # Identity
    fact_id: str = Field(..., description="ID of the ExtractedFact being classified")
    investigation_id: str = Field(..., description="Investigation scope")

    # Classification output
    impact_tier: ImpactTier = Field(
        ImpactTier.LESS_CRITICAL,
        description="critical or less_critical based on geopolitical significance"
    )
    dubious_flags: list[DubiousFlag] = Field(
        default_factory=list,
        description="List of doubt species (can be empty or multiple)"
    )

    # Scores
    priority_score: float = Field(
        0.0, ge=0.0, le=1.0,
        description="Impact × Fixability for Phase 8 queue ordering"
    )
    credibility_score: float = Field(
        0.0, ge=0.0, le=1.0,
        description="Composite credibility score"
    )
    credibility_breakdown: Optional[CredibilityBreakdown] = Field(
        None,
        description="Full breakdown for debugging and formula evolution"
    )

    # Reasoning
    classification_reasoning: list[ClassificationReasoning] = Field(
        default_factory=list,
        description="Explanation for each dubious flag"
    )
    impact_reasoning: Optional[str] = Field(
        None,
        description="Why this fact was classified as critical/less_critical"
    )

    # Audit trail
    history: list[ClassificationHistory] = Field(
        default_factory=list,
        description="Classification history for audit"
    )

    # Timestamps
    classified_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc)
    )
    updated_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc)
    )

    @property
    def is_dubious(self) -> bool:
        """Check if fact has any dubious flags."""
        return len(self.dubious_flags) > 0

    @property
    def is_critical_dubious(self) -> bool:
        """Check if fact is both critical AND dubious (priority verification)."""
        return self.impact_tier == ImpactTier.CRITICAL and self.is_dubious

    @property
    def is_noise(self) -> bool:
        """Check if fact is pure noise (batch analysis only, not individual verification)."""
        return DubiousFlag.NOISE in self.dubious_flags

    def add_history_entry(self, trigger: str) -> None:
        """Add current state to history before modification."""
        entry = ClassificationHistory(
            previous_impact_tier=self.impact_tier,
            previous_dubious_flags=list(self.dubious_flags),
            previous_credibility_score=self.credibility_score,
            trigger=trigger
        )
        self.history.append(entry)
        self.updated_at = datetime.now(timezone.utc)

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "fact_id": "uuid-fact-123",
                    "investigation_id": "inv-456",
                    "impact_tier": "critical",
                    "dubious_flags": ["phantom", "fog"],
                    "priority_score": 0.85,
                    "credibility_score": 0.45,
                    "credibility_breakdown": {
                        "s_root": 0.4,
                        "s_echoes_sum": 0.3,
                        "proximity_scores": [0.7, 0.49],
                        "precision_scores": [0.8, 0.6],
                        "echo_bonus": 0.05
                    },
                    "classification_reasoning": [
                        {
                            "flag": "phantom",
                            "reason": "hop_count=4, no primary_source found",
                            "trigger_values": {"hop_count": 4}
                        }
                    ],
                    "classified_at": "2024-03-15T12:00:00Z",
                    "updated_at": "2024-03-15T12:00:00Z"
                }
            ]
        }
    }
```

**Update schemas/__init__.py:**
Add imports for classification schema exports:
```python
from osint_system.data_management.schemas.classification_schema import (
    FactClassification,
    ImpactTier,
    DubiousFlag,
    CredibilityBreakdown,
    ClassificationReasoning,
    ClassificationHistory,
)
```
  </action>
  <verify>
```bash
uv run python -c "
from osint_system.data_management.schemas import (
    FactClassification, ImpactTier, DubiousFlag, CredibilityBreakdown
)
classification = FactClassification(
    fact_id='test-fact',
    investigation_id='test-inv',
    impact_tier=ImpactTier.CRITICAL,
    credibility_score=0.75
)
print(f'fact_id: {classification.fact_id}')
print(f'is_dubious: {classification.is_dubious}')
print(f'is_critical_dubious: {classification.is_critical_dubious}')

# Add dubious flag
classification.dubious_flags.append(DubiousFlag.PHANTOM)
print(f'After adding phantom - is_dubious: {classification.is_dubious}')
print(f'is_critical_dubious: {classification.is_critical_dubious}')
print('Classification schema OK')
"
```
  </verify>
  <done>FactClassification schema with impact tiers, dubious flags, and audit trail</done>
</task>

<task type="auto">
  <name>Task 2: Implement ClassificationStore</name>
  <files>
    osint_system/data_management/classification_store.py
    osint_system/data_management/__init__.py
  </files>
  <action>
Create investigation-scoped classification storage following FactStore patterns.

**classification_store.py:**
```python
"""Classification storage with investigation-scoped persistence and indexed lookup.

Per Phase 7 CONTEXT.md: Classifications stored separately from facts.
Indexed for Phase 8 access patterns:
- Priority queue (ordered by priority_score) for general processing
- Flag-type indexes (all Phantoms, all Fogs, etc.) for specialized subroutines
"""

import asyncio
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger

from osint_system.data_management.schemas import (
    DubiousFlag,
    FactClassification,
    ImpactTier,
)


class ClassificationStore:
    """
    Storage adapter for fact classifications with investigation-based organization.

    Features:
    - Investigation-scoped storage (investigation_id as primary key)
    - O(1) lookup by fact_id
    - Indexed by dubious flag type for Phase 8 subroutines
    - Priority queue ordering by priority_score
    - Optional JSON persistence for beta
    - Thread-safe operations with asyncio locks

    Data structure:
    {
        "investigation_id": {
            "metadata": {...},
            "classifications": {
                "fact_id": FactClassification dict,
                ...
            },
            "flag_index": {
                "phantom": ["fact_id", ...],
                "fog": ["fact_id", ...],
                ...
            },
            "tier_index": {
                "critical": ["fact_id", ...],
                "less_critical": ["fact_id", ...]
            }
        }
    }
    """

    def __init__(self, persistence_path: Optional[str] = None):
        """
        Initialize classification store.

        Args:
            persistence_path: Optional path to JSON file for persistence.
                            If None, storage is memory-only.
        """
        self._storage: Dict[str, Dict[str, Any]] = {}
        self._lock = asyncio.Lock()
        self.persistence_path = Path(persistence_path) if persistence_path else None
        self.logger = logger.bind(component="ClassificationStore")

        if self.persistence_path and self.persistence_path.exists():
            self._load_from_file()

        self.logger.info(
            "ClassificationStore initialized",
            persistence_enabled=self.persistence_path is not None,
        )

    def _init_investigation(self, investigation_id: str) -> None:
        """Initialize storage structure for an investigation."""
        if investigation_id not in self._storage:
            self._storage[investigation_id] = {
                "metadata": {},
                "created_at": datetime.now(timezone.utc).isoformat(),
                "updated_at": datetime.now(timezone.utc).isoformat(),
                "classifications": {},
                "flag_index": {flag.value: [] for flag in DubiousFlag},
                "tier_index": {tier.value: [] for tier in ImpactTier},
            }

    async def save_classification(
        self,
        classification: FactClassification,
    ) -> Dict[str, Any]:
        """
        Save or update a classification.

        Args:
            classification: FactClassification to save

        Returns:
            Stats dict: {action, fact_id, investigation_id}
        """
        async with self._lock:
            investigation_id = classification.investigation_id
            fact_id = classification.fact_id
            self._init_investigation(investigation_id)

            inv = self._storage[investigation_id]
            is_update = fact_id in inv["classifications"]

            # Store classification
            inv["classifications"][fact_id] = classification.model_dump(mode="json")

            # Update flag indexes
            self._update_flag_indexes(inv, fact_id, classification)

            # Update tier indexes
            self._update_tier_indexes(inv, fact_id, classification)

            inv["updated_at"] = datetime.now(timezone.utc).isoformat()

            if self.persistence_path:
                self._save_to_file()

            action = "updated" if is_update else "created"
            self.logger.debug(
                f"Classification {action}",
                fact_id=fact_id,
                investigation_id=investigation_id,
            )

            return {
                "action": action,
                "fact_id": fact_id,
                "investigation_id": investigation_id,
            }

    async def save_classifications(
        self,
        investigation_id: str,
        classifications: List[FactClassification],
    ) -> Dict[str, Any]:
        """
        Save multiple classifications for an investigation.

        Args:
            investigation_id: Investigation identifier
            classifications: List of FactClassification objects

        Returns:
            Stats dict: {created, updated, total}
        """
        created = 0
        updated = 0

        for classification in classifications:
            if classification.investigation_id != investigation_id:
                self.logger.warning(
                    f"Skipping classification with mismatched investigation_id: "
                    f"{classification.investigation_id} != {investigation_id}"
                )
                continue

            result = await self.save_classification(classification)
            if result["action"] == "created":
                created += 1
            else:
                updated += 1

        return {
            "created": created,
            "updated": updated,
            "total": created + updated,
        }

    def _update_flag_indexes(
        self,
        inv: Dict[str, Any],
        fact_id: str,
        classification: FactClassification,
    ) -> None:
        """Update flag-type indexes for Phase 8 subroutine access."""
        # Remove from all flag indexes first
        for flag_list in inv["flag_index"].values():
            if fact_id in flag_list:
                flag_list.remove(fact_id)

        # Add to current flag indexes
        for flag in classification.dubious_flags:
            if fact_id not in inv["flag_index"][flag.value]:
                inv["flag_index"][flag.value].append(fact_id)

    def _update_tier_indexes(
        self,
        inv: Dict[str, Any],
        fact_id: str,
        classification: FactClassification,
    ) -> None:
        """Update impact tier indexes."""
        # Remove from all tier indexes first
        for tier_list in inv["tier_index"].values():
            if fact_id in tier_list:
                tier_list.remove(fact_id)

        # Add to current tier index
        tier_value = classification.impact_tier.value
        if fact_id not in inv["tier_index"][tier_value]:
            inv["tier_index"][tier_value].append(fact_id)

    async def get_classification(
        self,
        investigation_id: str,
        fact_id: str,
    ) -> Optional[Dict[str, Any]]:
        """Get classification by fact_id. O(1) lookup."""
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            return inv.get("classifications", {}).get(fact_id)

    async def get_by_flag(
        self,
        investigation_id: str,
        flag: DubiousFlag,
    ) -> List[Dict[str, Any]]:
        """Get all classifications with a specific dubious flag."""
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            fact_ids = inv.get("flag_index", {}).get(flag.value, [])
            classifications = inv.get("classifications", {})
            return [classifications[fid] for fid in fact_ids if fid in classifications]

    async def get_by_tier(
        self,
        investigation_id: str,
        tier: ImpactTier,
    ) -> List[Dict[str, Any]]:
        """Get all classifications with a specific impact tier."""
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            fact_ids = inv.get("tier_index", {}).get(tier.value, [])
            classifications = inv.get("classifications", {})
            return [classifications[fid] for fid in fact_ids if fid in classifications]

    async def get_priority_queue(
        self,
        investigation_id: str,
        exclude_noise: bool = True,
        limit: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        Get classifications ordered by priority_score descending.

        Per CONTEXT.md: Priority queue for Phase 8 general processing.

        Args:
            investigation_id: Investigation identifier
            exclude_noise: If True, exclude NOISE-flagged facts (batch analysis only)
            limit: Maximum classifications to return

        Returns:
            List of classifications sorted by priority_score descending
        """
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            classifications = list(inv.get("classifications", {}).values())

            if exclude_noise:
                noise_ids = set(inv.get("flag_index", {}).get("noise", []))
                classifications = [c for c in classifications if c["fact_id"] not in noise_ids]

            # Sort by priority_score descending
            classifications.sort(key=lambda c: c.get("priority_score", 0), reverse=True)

            if limit:
                return classifications[:limit]
            return classifications

    async def get_dubious_facts(
        self,
        investigation_id: str,
        exclude_noise: bool = True,
    ) -> List[Dict[str, Any]]:
        """Get all classifications with at least one dubious flag."""
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            classifications = inv.get("classifications", {})

            dubious = []
            for fact_id, classification in classifications.items():
                flags = classification.get("dubious_flags", [])
                if flags:
                    if exclude_noise and "noise" in flags and len(flags) == 1:
                        # Skip if ONLY noise (batch analysis only)
                        continue
                    dubious.append(classification)

            return dubious

    async def get_critical_dubious(
        self,
        investigation_id: str,
    ) -> List[Dict[str, Any]]:
        """Get high-priority facts: critical tier AND dubious (priority verification)."""
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            critical_ids = set(inv.get("tier_index", {}).get("critical", []))

            # Get all dubious fact IDs (excluding noise-only)
            dubious_ids = set()
            for flag, fact_ids in inv.get("flag_index", {}).items():
                if flag != "noise":
                    dubious_ids.update(fact_ids)

            # Intersection: critical AND dubious
            critical_dubious_ids = critical_ids & dubious_ids
            classifications = inv.get("classifications", {})

            return [
                classifications[fid]
                for fid in critical_dubious_ids
                if fid in classifications
            ]

    async def get_stats(self, investigation_id: str) -> Dict[str, Any]:
        """Get statistics for an investigation's classifications."""
        async with self._lock:
            inv = self._storage.get(investigation_id, {})
            if not inv:
                return {"exists": False, "investigation_id": investigation_id}

            classifications = inv.get("classifications", {})
            flag_index = inv.get("flag_index", {})
            tier_index = inv.get("tier_index", {})

            # Count dubious
            dubious_count = len([
                c for c in classifications.values()
                if c.get("dubious_flags")
            ])

            return {
                "exists": True,
                "investigation_id": investigation_id,
                "total_classifications": len(classifications),
                "critical_count": len(tier_index.get("critical", [])),
                "less_critical_count": len(tier_index.get("less_critical", [])),
                "dubious_count": dubious_count,
                "flag_counts": {
                    flag: len(fact_ids)
                    for flag, fact_ids in flag_index.items()
                },
                "created_at": inv.get("created_at"),
                "updated_at": inv.get("updated_at"),
            }

    async def delete_investigation(self, investigation_id: str) -> bool:
        """Delete an investigation and all its classifications."""
        async with self._lock:
            if investigation_id not in self._storage:
                return False

            del self._storage[investigation_id]

            if self.persistence_path:
                self._save_to_file()

            self.logger.info(f"Deleted investigation classifications: {investigation_id}")
            return True

    def _save_to_file(self) -> None:
        """Save to JSON file (synchronous)."""
        if not self.persistence_path:
            return
        try:
            self.persistence_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.persistence_path, "w") as f:
                json.dump(self._storage, f, indent=2, default=str)
        except Exception as e:
            self.logger.error(f"Failed to persist: {e}")

    def _load_from_file(self) -> None:
        """Load from JSON file (synchronous)."""
        if not self.persistence_path or not self.persistence_path.exists():
            return
        try:
            with open(self.persistence_path, "r") as f:
                self._storage = json.load(f)
            self.logger.info(f"Loaded from {self.persistence_path}")
        except Exception as e:
            self.logger.error(f"Failed to load: {e}")
            self._storage = {}
```

**Update data_management/__init__.py:**
Add ClassificationStore export.
  </action>
  <verify>
```bash
uv run python -c "
import asyncio
from osint_system.data_management.classification_store import ClassificationStore
from osint_system.data_management.schemas import FactClassification, ImpactTier, DubiousFlag

async def test():
    store = ClassificationStore()

    # Create test classifications
    c1 = FactClassification(
        fact_id='f1',
        investigation_id='inv-1',
        impact_tier=ImpactTier.CRITICAL,
        dubious_flags=[DubiousFlag.PHANTOM],
        priority_score=0.9,
        credibility_score=0.5
    )
    c2 = FactClassification(
        fact_id='f2',
        investigation_id='inv-1',
        impact_tier=ImpactTier.LESS_CRITICAL,
        dubious_flags=[DubiousFlag.NOISE],
        priority_score=0.2,
        credibility_score=0.2
    )

    await store.save_classification(c1)
    await store.save_classification(c2)

    # Test lookups
    by_phantom = await store.get_by_flag('inv-1', DubiousFlag.PHANTOM)
    print(f'Phantom flags: {len(by_phantom)}')
    assert len(by_phantom) == 1

    critical_dubious = await store.get_critical_dubious('inv-1')
    print(f'Critical dubious: {len(critical_dubious)}')
    assert len(critical_dubious) == 1

    queue = await store.get_priority_queue('inv-1', exclude_noise=True)
    print(f'Priority queue (no noise): {len(queue)}')
    assert len(queue) == 1  # c2 excluded (noise only)

    stats = await store.get_stats('inv-1')
    print(f'Stats: {stats}')
    print('ClassificationStore OK')

asyncio.run(test())
"
```
  </verify>
  <done>ClassificationStore with indexed access for Phase 8 patterns</done>
</task>

<task type="auto">
  <name>Task 3: Implement FactClassificationAgent shell</name>
  <files>
    osint_system/agents/sifters/fact_classification_agent.py
    osint_system/agents/sifters/__init__.py
  </files>
  <action>
Create FactClassificationAgent with structure ready for Plans 02 and 03.

**fact_classification_agent.py:**
```python
"""Fact classification agent for categorizing extracted facts.

Per Phase 7 CONTEXT.md:
- Impact tier (critical/less_critical) based on geopolitical significance
- Trust status via dubious flags (phantom/fog/anomaly/noise)
- Credibility scoring with full breakdown
- Classifications are SEPARATE from facts (facts immutable)

This plan provides the agent structure.
Plans 02/03 implement the actual scoring and detection logic.
"""

from typing import Any, Dict, List, Optional

from loguru import logger

from osint_system.agents.sifters.base_sifter import BaseSifter
from osint_system.data_management.classification_store import ClassificationStore
from osint_system.data_management.fact_store import FactStore
from osint_system.data_management.schemas import (
    CredibilityBreakdown,
    DubiousFlag,
    FactClassification,
    ImpactTier,
)


class FactClassificationAgent(BaseSifter):
    """
    Classifies extracted facts into impact tiers with dubious detection.

    Per Phase 7 CONTEXT.md:
    - Impact and trust are orthogonal dimensions
    - A fact can be both "critical" AND "dubious"
    - High-impact dubious facts get priority verification

    Classification flow:
    1. Compute credibility score (Plan 02)
    2. Assess impact tier (critical vs less-critical)
    3. Detect dubious flags via Boolean logic gates (Plan 03)
    4. Calculate priority score (Impact x Fixability)
    5. Store classification record

    Attributes:
        classification_store: Storage for classification records
        fact_store: Read access to facts being classified
    """

    def __init__(
        self,
        classification_store: Optional[ClassificationStore] = None,
        fact_store: Optional[FactStore] = None,
    ):
        """
        Initialize fact classification agent.

        Args:
            classification_store: Store for classification records (creates default if None)
            fact_store: Store for reading facts (creates default if None)
        """
        super().__init__(
            name="FactClassificationAgent",
            description="Classifies extracted facts into impact tiers with dubious detection",
        )
        self._classification_store = classification_store
        self._fact_store = fact_store
        self.logger = logger.bind(component="FactClassificationAgent")

        self.logger.info("FactClassificationAgent initialized")

    @property
    def classification_store(self) -> ClassificationStore:
        """Lazy initialization of classification store."""
        if self._classification_store is None:
            self._classification_store = ClassificationStore()
        return self._classification_store

    @property
    def fact_store(self) -> FactStore:
        """Lazy initialization of fact store."""
        if self._fact_store is None:
            self._fact_store = FactStore()
        return self._fact_store

    async def sift(self, content: dict) -> list[dict]:
        """
        Classify facts and return classifications.

        Args:
            content: {
                'facts': list of ExtractedFact dicts,
                'investigation_id': str
            }

        Returns:
            List of FactClassification dicts
        """
        facts = content.get("facts", [])
        investigation_id = content.get("investigation_id", "default")

        if not facts:
            self.logger.warning("No facts to classify")
            return []

        classifications = []
        for fact in facts:
            try:
                classification = await self.classify_fact(fact, investigation_id)
                classifications.append(classification.model_dump(mode="json"))
            except Exception as e:
                self.logger.error(
                    f"Failed to classify fact {fact.get('fact_id', 'unknown')}: {e}",
                    exc_info=True,
                )
                continue

        # Save all classifications
        if classifications:
            await self.classification_store.save_classifications(
                investigation_id,
                [FactClassification(**c) for c in classifications],
            )

        self.logger.info(
            f"Classified {len(classifications)} facts",
            investigation_id=investigation_id,
        )

        return classifications

    async def classify_fact(
        self,
        fact: Dict[str, Any],
        investigation_id: str,
    ) -> FactClassification:
        """
        Classify a single fact.

        Args:
            fact: ExtractedFact dict
            investigation_id: Investigation scope

        Returns:
            FactClassification for the fact
        """
        fact_id = fact.get("fact_id", "unknown")

        # Step 1: Compute credibility score (Plan 02 implements this)
        credibility_score, credibility_breakdown = self._compute_credibility(fact)

        # Step 2: Assess impact tier
        impact_tier, impact_reasoning = self._assess_impact(fact, investigation_id)

        # Step 3: Detect dubious flags (Plan 03 implements this)
        dubious_flags, classification_reasoning = self._detect_dubious(
            fact, credibility_score
        )

        # Step 4: Calculate priority score (Impact x Fixability)
        priority_score = self._calculate_priority(
            impact_tier, dubious_flags, credibility_score
        )

        classification = FactClassification(
            fact_id=fact_id,
            investigation_id=investigation_id,
            impact_tier=impact_tier,
            dubious_flags=dubious_flags,
            priority_score=priority_score,
            credibility_score=credibility_score,
            credibility_breakdown=credibility_breakdown,
            classification_reasoning=classification_reasoning,
            impact_reasoning=impact_reasoning,
        )

        self.logger.debug(
            f"Classified fact {fact_id}",
            impact=impact_tier.value,
            dubious_count=len(dubious_flags),
            credibility=credibility_score,
            priority=priority_score,
        )

        return classification

    def _compute_credibility(
        self,
        fact: Dict[str, Any],
    ) -> tuple[float, Optional[CredibilityBreakdown]]:
        """
        Compute credibility score for a fact.

        Per CONTEXT.md formula: Claim Score = Σ(SourceCred × Proximity × Precision)
        Plus logarithmic echo dampening.

        Plan 02 implements the full algorithm. This is the shell.

        Returns:
            (credibility_score, breakdown)
        """
        # Placeholder: Plan 02 implements actual algorithm
        quality = fact.get("quality", {})
        claim_clarity = quality.get("claim_clarity", 0.5) if quality else 0.5

        # Basic fallback: use claim_clarity as proxy
        return claim_clarity, None

    def _assess_impact(
        self,
        fact: Dict[str, Any],
        investigation_id: str,
    ) -> tuple[ImpactTier, Optional[str]]:
        """
        Assess impact tier based on geopolitical significance.

        Per CONTEXT.md: Impact based on:
        - Entity significance (world leaders > local officials)
        - Event type (military action > diplomatic meeting > routine statement)
        - Investigation context (recency, objective relevance)

        Plan 03 implements the full algorithm. This is the shell.

        Returns:
            (impact_tier, reasoning)
        """
        # Placeholder: Plan 03 implements context-aware impact assessment
        # For now: default to less_critical
        return ImpactTier.LESS_CRITICAL, "Default classification pending full implementation"

    def _detect_dubious(
        self,
        fact: Dict[str, Any],
        credibility_score: float,
    ) -> tuple[list[DubiousFlag], list]:
        """
        Detect dubious flags using Boolean logic gates.

        Per CONTEXT.md taxonomy:
        - PHANTOM: hop_count > 2 AND primary_source IS NULL
        - FOG: claim_clarity < 0.5 OR attribution ~= "sources say"
        - ANOMALY: contradiction_count > 0
        - NOISE: source_credibility < 0.3

        Plan 03 implements the full detection logic. This is the shell.

        Returns:
            (dubious_flags, classification_reasoning)
        """
        # Placeholder: Plan 03 implements Boolean logic gates
        flags: List[DubiousFlag] = []
        reasoning: List[Dict[str, Any]] = []

        # Basic noise detection based on credibility
        if credibility_score < 0.3:
            flags.append(DubiousFlag.NOISE)
            reasoning.append({
                "flag": DubiousFlag.NOISE.value,
                "reason": f"credibility_score ({credibility_score:.2f}) < 0.3",
                "trigger_values": {"credibility_score": credibility_score},
            })

        return flags, reasoning

    def _calculate_priority(
        self,
        impact_tier: ImpactTier,
        dubious_flags: List[DubiousFlag],
        credibility_score: float,
    ) -> float:
        """
        Calculate priority score for Phase 8 queue ordering.

        Per CONTEXT.md: Priority = Impact × Fixability
        - High-impact fixable claims get priority
        - NOISE does not enter individual verification queue

        Returns:
            Priority score 0.0-1.0
        """
        # Impact factor
        impact_factor = 1.0 if impact_tier == ImpactTier.CRITICAL else 0.5

        # Fixability factor (NOISE is not fixable individually)
        if DubiousFlag.NOISE in dubious_flags and len(dubious_flags) == 1:
            # Pure noise: batch analysis only, no individual verification
            fixability = 0.0
        elif not dubious_flags:
            # Not dubious: no verification needed
            fixability = 0.0
        else:
            # Dubious but fixable: higher credibility = easier to verify
            # (more likely to find corroborating sources)
            fixability = 0.3 + (credibility_score * 0.7)

        return impact_factor * fixability

    async def reclassify_fact(
        self,
        investigation_id: str,
        fact_id: str,
        trigger: str,
    ) -> Optional[FactClassification]:
        """
        Re-classify a fact (e.g., after new corroborating evidence).

        Per CONTEXT.md: Classifications are dynamic, update as new info arrives.

        Args:
            investigation_id: Investigation scope
            fact_id: Fact to re-classify
            trigger: What triggered re-classification

        Returns:
            Updated classification, or None if fact not found
        """
        # Get current classification
        current = await self.classification_store.get_classification(
            investigation_id, fact_id
        )
        if not current:
            self.logger.warning(f"No classification found for {fact_id}")
            return None

        # Get fact from fact store
        fact = await self.fact_store.get_fact(investigation_id, fact_id)
        if not fact:
            self.logger.warning(f"Fact not found: {fact_id}")
            return None

        # Re-classify
        new_classification = await self.classify_fact(fact, investigation_id)

        # Add history entry
        new_classification.add_history_entry(trigger)

        # Save updated classification
        await self.classification_store.save_classification(new_classification)

        self.logger.info(f"Re-classified fact {fact_id}", trigger=trigger)

        return new_classification

    async def get_classification_stats(
        self,
        investigation_id: str,
    ) -> Dict[str, Any]:
        """Get classification statistics for an investigation."""
        return await self.classification_store.get_stats(investigation_id)

    def get_capabilities(self) -> list[str]:
        """Return agent capabilities."""
        return [
            "fact_classification",
            "impact_assessment",
            "dubious_detection",
            "credibility_scoring",
            "priority_calculation",
        ]
```

**Update sifters/__init__.py:**
Add FactClassificationAgent to exports:
```python
from osint_system.agents.sifters.fact_classification_agent import FactClassificationAgent
```
And add to __all__ list.
  </action>
  <verify>
```bash
uv run python -c "
import asyncio
from osint_system.agents.sifters import FactClassificationAgent
from osint_system.data_management.schemas import ImpactTier, DubiousFlag

async def test():
    agent = FactClassificationAgent()
    print(f'Agent: {agent.name}')
    print(f'Capabilities: {agent.get_capabilities()}')

    # Test classification
    facts = [
        {
            'fact_id': 'test-f1',
            'claim': {'text': '[E1:Putin] visited [E2:Beijing]'},
            'quality': {'extraction_confidence': 0.9, 'claim_clarity': 0.8},
            'provenance': {'source_id': 'src-1', 'hop_count': 1}
        },
        {
            'fact_id': 'test-f2',
            'claim': {'text': 'Sources suggest activity'},
            'quality': {'extraction_confidence': 0.7, 'claim_clarity': 0.2},
            'provenance': {'source_id': 'src-2', 'hop_count': 3}
        }
    ]

    classifications = await agent.sift({
        'facts': facts,
        'investigation_id': 'test-inv'
    })

    print(f'Classified {len(classifications)} facts')
    for c in classifications:
        print(f'  {c[\"fact_id\"]}: {c[\"impact_tier\"]}, dubious: {c[\"dubious_flags\"]}')

    stats = await agent.get_classification_stats('test-inv')
    print(f'Stats: {stats}')
    print('FactClassificationAgent OK')

asyncio.run(test())
"
```
  </verify>
  <done>FactClassificationAgent shell ready for Plans 02/03 algorithm implementation</done>
</task>

<task type="auto">
  <name>Task 4: Add tests for schemas and agent</name>
  <files>
    tests/data_management/schemas/test_classification_schema.py
    tests/agents/sifters/test_fact_classification_agent.py
  </files>
  <action>
Create comprehensive tests for classification schemas and agent.

**test_classification_schema.py:**
Test cases:
1. FactClassification creation with minimal fields
2. FactClassification with full fields
3. is_dubious property
4. is_critical_dubious property
5. is_noise property
6. add_history_entry method
7. CredibilityBreakdown.compute_total()
8. ImpactTier enum values
9. DubiousFlag enum values

**test_fact_classification_agent.py:**
Test cases:
1. Agent initialization
2. Agent capabilities
3. sift() with empty facts
4. sift() with valid facts
5. classify_fact() basic flow
6. priority calculation logic
7. Classification store integration
8. Re-classification with history

Use pytest and follow existing test patterns.
  </action>
  <verify>
```bash
uv run python -m pytest tests/data_management/schemas/test_classification_schema.py tests/agents/sifters/test_fact_classification_agent.py -v
```
  </verify>
  <done>All classification tests pass</done>
</task>

</tasks>

<verification>
```bash
# All imports work
uv run python -c "
from osint_system.data_management.schemas import (
    FactClassification, ImpactTier, DubiousFlag,
    CredibilityBreakdown, ClassificationReasoning, ClassificationHistory
)
from osint_system.data_management.classification_store import ClassificationStore
from osint_system.agents.sifters import FactClassificationAgent
print('All classification imports OK')
"

# Tests pass
uv run python -m pytest tests/data_management/schemas/test_classification_schema.py tests/agents/sifters/test_fact_classification_agent.py -v

# Integration check
uv run python -c "
import asyncio
from osint_system.agents.sifters import FactClassificationAgent

async def integration():
    agent = FactClassificationAgent()

    facts = [
        {
            'fact_id': 'int-f1',
            'claim': {'text': 'Test fact'},
            'quality': {'claim_clarity': 0.7}
        }
    ]

    results = await agent.sift({
        'facts': facts,
        'investigation_id': 'int-test'
    })

    assert len(results) == 1
    print(f'Classification: {results[0]}')
    print('Integration OK')

asyncio.run(integration())
"
```
</verification>

<success_criteria>
- FactClassification schema validates with required fields
- Dubious flags are independent and combinable
- Impact tier and dubious status are orthogonal
- ClassificationStore provides O(1) lookup by fact_id
- ClassificationStore provides indexed access by flag type
- Priority queue excludes NOISE-only classifications
- FactClassificationAgent inherits from BaseSifter
- Agent shell ready for Plans 02/03 algorithm implementation
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-fact-classification-system/07-01-SUMMARY.md`
</output>
