---
phase: 07-fact-classification-system
plan: 03
type: execute
wave: 3
depends_on: ["07-02"]
files_modified:
  - osint_system/agents/sifters/classification/__init__.py
  - osint_system/agents/sifters/classification/dubious_detector.py
  - osint_system/config/prompts/classification_prompts.py
  - tests/agents/sifters/classification/__init__.py
  - tests/agents/sifters/classification/test_dubious_detector.py
autonomous: true

must_haves:
  truths:
    - "Dubious detection uses Boolean logic gates, NOT weighted formulas"
    - "PHANTOM: hop_count > 2 AND primary_source IS NULL"
    - "FOG: claim_clarity < 0.5 OR attribution contains vague patterns"
    - "ANOMALY: contradiction_count > 0 (input from external detector)"
    - "NOISE: source_credibility < 0.3 (batch analysis only, not individual verification)"
  artifacts:
    - path: "osint_system/agents/sifters/classification/dubious_detector.py"
      provides: "DubiousDetector with Boolean logic gates for taxonomy of doubt"
      exports: ["DubiousDetector", "DubiousResult"]
      min_lines: 180
    - path: "osint_system/config/prompts/classification_prompts.py"
      provides: "Classification prompts and vague attribution patterns"
      exports: ["VAGUE_ATTRIBUTION_PATTERNS", "CRITICAL_ENTITY_PATTERNS", "CRITICAL_EVENT_KEYWORDS"]
      min_lines: 60
  key_links:
    - from: "osint_system/agents/sifters/classification/dubious_detector.py"
      to: "osint_system/config/prompts/classification_prompts.py"
      via: "VAGUE_ATTRIBUTION_PATTERNS for FOG detection"
      pattern: "from.*classification_prompts.*import.*VAGUE_ATTRIBUTION_PATTERNS"
    - from: "osint_system/agents/sifters/classification/dubious_detector.py"
      to: "osint_system/data_management/schemas/classification_schema.py"
      via: "DubiousFlag and ClassificationReasoning schemas"
      pattern: "from.*classification_schema.*import.*DubiousFlag"
---

<objective>
Implement DubiousDetector with Boolean logic gates and classification prompts.

Purpose: The Taxonomy of Doubt uses Boolean logic gates (not weighted formulas) to classify dubious facts by species. Each species triggers a specific Phase 8 verification subroutine. This plan provides the core detection logic; Plan 04 adds ImpactAssessor, AnomalyDetector, and full agent integration.

Output: DubiousDetector with PHANTOM/FOG/NOISE detection, plus classification prompt templates.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-fact-classification-system/07-CONTEXT.md
@.planning/phases/07-fact-classification-system/07-01-SUMMARY.md
@.planning/phases/07-fact-classification-system/07-02-SUMMARY.md

# Schemas we use
@osint_system/data_management/schemas/fact_schema.py
@osint_system/data_management/schemas/classification_schema.py
@osint_system/config/source_credibility.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create classification prompts for LLM-assisted assessment</name>
  <files>osint_system/config/prompts/classification_prompts.py</files>
  <action>
Create prompts for LLM-assisted impact assessment (entity significance, event type).

**classification_prompts.py:**
```python
"""Prompt templates for fact classification per Phase 7 CONTEXT.md.

LLM-assisted classification for:
- Entity significance assessment (world leaders, officials, etc.)
- Event type categorization (military action, diplomatic, routine)
- Vague attribution pattern detection

The Boolean logic gates for dubious detection are rule-based.
LLM assists with semantic understanding where rules are insufficient.
"""

ENTITY_SIGNIFICANCE_PROMPT = '''Assess the geopolitical significance of entities in this fact.

FACT:
{fact_text}

ENTITIES:
{entities}

Rate each entity's significance for geopolitical analysis:
- world_leader (1.0): Heads of state, prime ministers
- senior_official (0.8): Cabinet members, ambassadors, military commanders
- government_official (0.6): Lower-ranking officials, spokespersons
- company_executive (0.5): CEOs, executives of major companies
- organization (0.4): Named organizations, agencies
- public_figure (0.4): Known individuals without official capacity
- location_major (0.6): Capitals, major cities, strategic locations
- location_minor (0.3): Minor locations

Return JSON:
{{
    "entities": [
        {{"id": "E1", "text": "...", "significance": "world_leader", "score": 1.0}},
        ...
    ],
    "overall_significance": 0.0-1.0
}}'''


EVENT_TYPE_PROMPT = '''Categorize the event type in this fact for geopolitical impact assessment.

FACT:
{fact_text}

CLAIM TYPE: {claim_type}
ASSERTION TYPE: {assertion_type}

Categorize the event:
- military_action (1.0): Combat, troop movements, weapons deployment
- treaty_agreement (0.9): Formal agreements, treaties, accords
- sanctions (0.9): Economic sanctions, embargoes, restrictions
- diplomatic_meeting (0.7): Summits, official visits, negotiations
- policy_announcement (0.6): Policy changes, new regulations
- official_statement (0.5): Press releases, spokesperson comments
- routine_activity (0.2): Regular operations, standard procedures

Return JSON:
{{
    "event_type": "military_action|treaty_agreement|...",
    "score": 0.0-1.0,
    "reasoning": "brief explanation"
}}'''


VAGUE_ATTRIBUTION_PATTERNS = [
    # English vague patterns
    r"sources?\s+(?:say|said|claim|suggest|indicate)",
    r"according\s+to\s+(?:sources?|officials?|reports?)",
    r"reportedly",
    r"allegedly",
    r"it\s+is\s+(?:said|believed|reported|understood)",
    r"(?:some|many|several)\s+(?:say|believe|think)",
    r"(?:anonymous|unnamed)\s+(?:source|official)",
    r"people\s+familiar\s+with",
    r"those\s+close\s+to",
    r"insiders?\s+(?:say|claim)",

    # Hedging language
    r"(?:may|might|could)\s+(?:have|be)",
    r"appears?\s+to",
    r"seems?\s+(?:to|like)",
    r"(?:likely|probably|possibly)",
]


# Impact assessment context patterns
CRITICAL_ENTITY_PATTERNS = [
    # World leaders (regex patterns)
    r"(?:president|prime\s+minister|chancellor|king|queen)\s+\w+",
    r"(?:xi|putin|biden|modi|macron|scholz|sunak)",

    # Organizations
    r"(?:nato|un|eu|g7|g20|brics|asean|opec)",
    r"(?:pentagon|kremlin|white\s+house|downing\s+street)",

    # Military
    r"(?:army|navy|air\s+force|military|troops|soldiers)",
    r"(?:nuclear|missile|weapon|bomb)",
]

CRITICAL_EVENT_KEYWORDS = [
    # Military
    "attack", "strike", "invasion", "war", "conflict", "military",
    "nuclear", "missile", "weapon", "troops", "soldiers", "combat",

    # Diplomatic
    "summit", "treaty", "agreement", "sanction", "embargo",
    "diplomatic", "ambassador", "negotiation",

    # Major events
    "election", "coup", "assassination", "emergency", "crisis",
]
```
  </action>
  <verify>
```bash
uv run python -c "
from osint_system.config.prompts.classification_prompts import (
    ENTITY_SIGNIFICANCE_PROMPT,
    EVENT_TYPE_PROMPT,
    VAGUE_ATTRIBUTION_PATTERNS,
    CRITICAL_ENTITY_PATTERNS,
    CRITICAL_EVENT_KEYWORDS,
)

print(f'Entity prompt: {len(ENTITY_SIGNIFICANCE_PROMPT)} chars')
print(f'Event prompt: {len(EVENT_TYPE_PROMPT)} chars')
print(f'Vague patterns: {len(VAGUE_ATTRIBUTION_PATTERNS)}')
print(f'Critical entity patterns: {len(CRITICAL_ENTITY_PATTERNS)}')
print(f'Critical keywords: {len(CRITICAL_EVENT_KEYWORDS)}')
print('Classification prompts OK')
"
```
  </verify>
  <done>Classification prompts and pattern definitions for LLM-assisted assessment</done>
</task>

<task type="auto">
  <name>Task 2: Implement DubiousDetector with Boolean logic gates</name>
  <files>
    osint_system/agents/sifters/classification/__init__.py
    osint_system/agents/sifters/classification/dubious_detector.py
  </files>
  <action>
Create DubiousDetector implementing the Taxonomy of Doubt with Boolean logic gates.

**dubious_detector.py:**
```python
"""Dubious detection using Boolean logic gates per Phase 7 CONTEXT.md.

The Taxonomy of Doubt identifies the SPECIES of doubt, not magnitude.
Each species triggers a specific Phase 8 verification subroutine.

| Species   | Trigger (Logic Gate)                        | Signal             | Phase 8 Action          |
|-----------|---------------------------------------------|--------------------| ------------------------|
| PHANTOM   | hop_count > 2 AND primary_source IS NULL    | Echo without root  | Trace back to find root |
| FOG       | claim_clarity < 0.5 OR vague attribution    | Speaker is mumbling| Find harder claim       |
| ANOMALY   | contradiction_count > 0                     | Sources disagree   | Arbitrate               |
| NOISE     | source_credibility < 0.3                    | Known unreliable   | Batch analysis only     |

CRITICAL: Uses Boolean logic gates, NOT weighted formulas.
"""

import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

from loguru import logger

from osint_system.config.prompts.classification_prompts import VAGUE_ATTRIBUTION_PATTERNS
from osint_system.data_management.schemas import ClassificationReasoning, DubiousFlag


@dataclass
class DubiousResult:
    """Result of dubious detection."""
    flags: List[DubiousFlag] = field(default_factory=list)
    reasoning: List[ClassificationReasoning] = field(default_factory=list)
    fixability_score: float = 0.0  # How easily can this be verified?


class DubiousDetector:
    """
    Detects dubious facts using Boolean logic gates.

    Per CONTEXT.md: Dubious classification identifies the SPECIES of doubt,
    not magnitude. Each species triggers a specific Phase 8 subroutine.

    Flags are independent - a fact can have multiple flags (Phantom + Fog).

    Usage:
        detector = DubiousDetector()
        result = detector.detect(fact, credibility_score, contradictions)
    """

    # Thresholds (from CONTEXT.md)
    PHANTOM_HOP_THRESHOLD = 2
    FOG_CLARITY_THRESHOLD = 0.5
    NOISE_CREDIBILITY_THRESHOLD = 0.3

    def __init__(
        self,
        phantom_hop_threshold: int = PHANTOM_HOP_THRESHOLD,
        fog_clarity_threshold: float = FOG_CLARITY_THRESHOLD,
        noise_credibility_threshold: float = NOISE_CREDIBILITY_THRESHOLD,
    ):
        """
        Initialize dubious detector with configurable thresholds.

        Args:
            phantom_hop_threshold: hop_count above which PHANTOM triggers (default 2)
            fog_clarity_threshold: claim_clarity below which FOG triggers (default 0.5)
            noise_credibility_threshold: credibility below which NOISE triggers (default 0.3)
        """
        self.phantom_hop_threshold = phantom_hop_threshold
        self.fog_clarity_threshold = fog_clarity_threshold
        self.noise_credibility_threshold = noise_credibility_threshold
        self.vague_patterns = [re.compile(p, re.IGNORECASE) for p in VAGUE_ATTRIBUTION_PATTERNS]
        self.logger = logger.bind(component="DubiousDetector")

    def detect(
        self,
        fact: Dict[str, Any],
        credibility_score: float,
        contradictions: Optional[List[Dict[str, Any]]] = None,
    ) -> DubiousResult:
        """
        Detect dubious flags for a fact using Boolean logic gates.

        Args:
            fact: ExtractedFact dict
            credibility_score: Pre-computed credibility score
            contradictions: List of contradicting facts (from AnomalyDetector)

        Returns:
            DubiousResult with flags and reasoning
        """
        result = DubiousResult()

        # Gate 1: PHANTOM (Structural Failure)
        phantom_result = self._check_phantom(fact)
        if phantom_result:
            result.flags.append(DubiousFlag.PHANTOM)
            result.reasoning.append(phantom_result)

        # Gate 2: FOG (Attribution Failure)
        fog_result = self._check_fog(fact)
        if fog_result:
            result.flags.append(DubiousFlag.FOG)
            result.reasoning.append(fog_result)

        # Gate 3: ANOMALY (Coherence Failure)
        if contradictions:
            anomaly_result = self._check_anomaly(fact, contradictions)
            if anomaly_result:
                result.flags.append(DubiousFlag.ANOMALY)
                result.reasoning.append(anomaly_result)

        # Gate 4: NOISE (Reputation Failure)
        noise_result = self._check_noise(credibility_score)
        if noise_result:
            result.flags.append(DubiousFlag.NOISE)
            result.reasoning.append(noise_result)

        # Calculate fixability
        result.fixability_score = self._calculate_fixability(result.flags, credibility_score)

        self.logger.debug(
            f"Dubious detection: {[f.value for f in result.flags]}",
            fact_id=fact.get("fact_id", "unknown")[:20],
            fixability=result.fixability_score,
        )

        return result

    def _check_phantom(self, fact: Dict[str, Any]) -> Optional[ClassificationReasoning]:
        """
        Gate 1: PHANTOM - Structural Failure.

        Trigger: hop_count > 2 AND primary_source IS NULL
        Signal: Echo without speaker - no traceable root source.

        Returns:
            ClassificationReasoning if triggered, None otherwise
        """
        provenance = fact.get("provenance", {})
        hop_count = provenance.get("hop_count", 0)

        # Check hop count threshold
        if hop_count <= self.phantom_hop_threshold:
            return None

        # Check for primary source
        has_primary = self._has_primary_source(provenance)
        if has_primary:
            return None

        # Both conditions met: PHANTOM triggered
        return ClassificationReasoning(
            flag=DubiousFlag.PHANTOM,
            reason=f"hop_count={hop_count} > {self.phantom_hop_threshold} AND no primary source found",
            trigger_values={
                "hop_count": hop_count,
                "primary_source": None,
                "threshold": self.phantom_hop_threshold,
            },
        )

    def _has_primary_source(self, provenance: Dict[str, Any]) -> bool:
        """Check if provenance has a traceable primary source."""
        # Check source classification
        if provenance.get("source_classification") == "primary":
            return True

        # Check attribution chain for hop=0 entity
        attribution_chain = provenance.get("attribution_chain", [])
        for hop in attribution_chain:
            if hop.get("hop", 999) == 0:
                return True

        # Check if hop_count is 0 (direct source)
        if provenance.get("hop_count", 1) == 0:
            return True

        return False

    def _check_fog(self, fact: Dict[str, Any]) -> Optional[ClassificationReasoning]:
        """
        Gate 2: FOG - Attribution Failure.

        Trigger: claim_clarity < 0.5 OR attribution contains vague patterns
        Signal: Speaker is mumbling - unclear who said what.

        Returns:
            ClassificationReasoning if triggered, None otherwise
        """
        quality = fact.get("quality", {})
        claim_clarity = quality.get("claim_clarity", 1.0) if quality else 1.0
        provenance = fact.get("provenance", {})
        attribution_phrase = provenance.get("attribution_phrase", "")

        trigger_values: Dict[str, Any] = {}
        reasons = []

        # Condition 1: Low claim clarity
        if claim_clarity < self.fog_clarity_threshold:
            reasons.append(f"claim_clarity={claim_clarity:.2f} < {self.fog_clarity_threshold}")
            trigger_values["claim_clarity"] = claim_clarity
            trigger_values["clarity_threshold"] = self.fog_clarity_threshold

        # Condition 2: Vague attribution patterns
        vague_match = self._check_vague_attribution(attribution_phrase)
        if vague_match:
            reasons.append(f"attribution contains vague pattern: '{vague_match}'")
            trigger_values["attribution_phrase"] = attribution_phrase
            trigger_values["vague_pattern"] = vague_match

        # Also check claim text for hedging
        claim_text = fact.get("claim", {}).get("text", "")
        claim_vague = self._check_vague_attribution(claim_text)
        if claim_vague and claim_vague not in trigger_values.get("vague_pattern", ""):
            reasons.append(f"claim contains vague language: '{claim_vague}'")
            trigger_values["claim_vague_pattern"] = claim_vague

        if not reasons:
            return None

        return ClassificationReasoning(
            flag=DubiousFlag.FOG,
            reason=" OR ".join(reasons),
            trigger_values=trigger_values,
        )

    def _check_vague_attribution(self, text: str) -> Optional[str]:
        """Check text for vague attribution patterns."""
        if not text:
            return None

        for pattern in self.vague_patterns:
            match = pattern.search(text)
            if match:
                return match.group(0)

        return None

    def _check_anomaly(
        self,
        fact: Dict[str, Any],
        contradictions: List[Dict[str, Any]],
    ) -> Optional[ClassificationReasoning]:
        """
        Gate 3: ANOMALY - Coherence Failure.

        Trigger: contradiction_count > 0
        Signal: Trusted systems disagree - needs arbitration.

        Returns:
            ClassificationReasoning if triggered, None otherwise
        """
        if not contradictions:
            return None

        contradiction_count = len(contradictions)
        if contradiction_count == 0:
            return None

        # Build contradiction summary
        contradiction_ids = [c.get("fact_id", "unknown") for c in contradictions[:5]]

        return ClassificationReasoning(
            flag=DubiousFlag.ANOMALY,
            reason=f"contradiction_count={contradiction_count} > 0",
            trigger_values={
                "contradiction_count": contradiction_count,
                "contradicting_fact_ids": contradiction_ids,
            },
        )

    def _check_noise(self, credibility_score: float) -> Optional[ClassificationReasoning]:
        """
        Gate 4: NOISE - Reputation Failure.

        Trigger: source_credibility < 0.3
        Signal: Known unreliable source - batch analysis only.

        Per CONTEXT.md: NOISE does NOT enter individual verification queue.
        Batch analysis only - aggregate for pattern detection.

        Returns:
            ClassificationReasoning if triggered, None otherwise
        """
        if credibility_score >= self.noise_credibility_threshold:
            return None

        return ClassificationReasoning(
            flag=DubiousFlag.NOISE,
            reason=f"credibility_score={credibility_score:.2f} < {self.noise_credibility_threshold}",
            trigger_values={
                "credibility_score": credibility_score,
                "threshold": self.noise_credibility_threshold,
            },
        )

    def _calculate_fixability(
        self,
        flags: List[DubiousFlag],
        credibility_score: float,
    ) -> float:
        """
        Calculate how easily this fact can be verified.

        Per CONTEXT.md: Priority = Impact x Fixability
        High-impact fixable claims get priority.

        Fixability factors:
        - PHANTOM: Moderately fixable (trace back to root)
        - FOG: Highly fixable (find clearer statement)
        - ANOMALY: Highly fixable (arbitrate with context)
        - NOISE: Not individually fixable (batch only)

        Returns:
            Fixability score 0.0-1.0
        """
        if not flags:
            return 0.0  # Not dubious, no verification needed

        # Pure NOISE is not individually fixable
        if DubiousFlag.NOISE in flags and len(flags) == 1:
            return 0.0

        fixability_scores = {
            DubiousFlag.FOG: 0.9,      # Easy to find clearer source
            DubiousFlag.ANOMALY: 0.8,  # Can arbitrate with context
            DubiousFlag.PHANTOM: 0.6,  # Harder to trace root
            DubiousFlag.NOISE: 0.1,    # Only as part of other flags
        }

        # Take highest fixability (most promising verification route)
        max_fixability = max(fixability_scores.get(f, 0.5) for f in flags)

        # Slightly boost if higher credibility (easier to find corroboration)
        credibility_boost = credibility_score * 0.2

        return min(1.0, max_fixability + credibility_boost)


__all__ = ["DubiousDetector", "DubiousResult"]
```

**classification/__init__.py:**
```python
"""Classification logic components for fact classification."""

from osint_system.agents.sifters.classification.dubious_detector import (
    DubiousDetector,
    DubiousResult,
)

__all__ = [
    "DubiousDetector",
    "DubiousResult",
]
```
  </action>
  <verify>
```bash
uv run python -c "
from osint_system.agents.sifters.classification import DubiousDetector, DubiousResult
from osint_system.data_management.schemas import DubiousFlag

detector = DubiousDetector()

# Test PHANTOM detection
phantom_fact = {
    'fact_id': 'phantom-1',
    'claim': {'text': 'Some claim'},
    'provenance': {
        'hop_count': 4,
        'source_classification': 'tertiary',
        'attribution_chain': [
            {'entity': 'unnamed source', 'hop': 2}
        ]
    }
}
result = detector.detect(phantom_fact, credibility_score=0.5)
print(f'PHANTOM test: {[f.value for f in result.flags]}')
assert DubiousFlag.PHANTOM in result.flags, 'Should detect PHANTOM'

# Test FOG detection
fog_fact = {
    'fact_id': 'fog-1',
    'claim': {'text': 'Sources suggest something happened'},
    'quality': {'claim_clarity': 0.3, 'extraction_confidence': 0.8},
    'provenance': {
        'attribution_phrase': 'according to sources familiar with the matter'
    }
}
result = detector.detect(fog_fact, credibility_score=0.6)
print(f'FOG test: {[f.value for f in result.flags]}')
assert DubiousFlag.FOG in result.flags, 'Should detect FOG'

# Test NOISE detection
result = detector.detect({'fact_id': 'noise-1', 'claim': {'text': 'x'}}, credibility_score=0.2)
print(f'NOISE test: {[f.value for f in result.flags]}')
assert DubiousFlag.NOISE in result.flags, 'Should detect NOISE'

# Test ANOMALY detection
result = detector.detect(
    {'fact_id': 'anomaly-1', 'claim': {'text': 'x'}},
    credibility_score=0.7,
    contradictions=[{'fact_id': 'contra-1', 'claim': {'text': 'y'}}]
)
print(f'ANOMALY test: {[f.value for f in result.flags]}')
assert DubiousFlag.ANOMALY in result.flags, 'Should detect ANOMALY'

print('DubiousDetector OK')
"
```
  </verify>
  <done>DubiousDetector with Boolean logic gates for all four species</done>
</task>

<task type="auto">
  <name>Task 3: Add DubiousDetector tests</name>
  <files>
    tests/agents/sifters/classification/__init__.py
    tests/agents/sifters/classification/test_dubious_detector.py
  </files>
  <action>
Create comprehensive tests for DubiousDetector.

**test_dubious_detector.py:**
Test cases:
1. PHANTOM detection (high hop + no primary)
2. PHANTOM not triggered (has primary source)
3. FOG detection (low claim_clarity)
4. FOG detection (vague attribution patterns)
5. FOG patterns: "reportedly", "sources say", "allegedly"
6. ANOMALY detection with contradictions
7. NOISE detection (low credibility)
8. Multiple flags (PHANTOM + FOG)
9. Clean fact (no flags)
10. Fixability score calculation

Create tests/agents/sifters/classification/__init__.py (empty).
  </action>
  <verify>
```bash
uv run python -m pytest tests/agents/sifters/classification/test_dubious_detector.py -v
```
  </verify>
  <done>All DubiousDetector tests pass</done>
</task>

</tasks>

<verification>
```bash
# All imports work
uv run python -c "
from osint_system.agents.sifters.classification import DubiousDetector, DubiousResult
from osint_system.config.prompts.classification_prompts import (
    VAGUE_ATTRIBUTION_PATTERNS, CRITICAL_ENTITY_PATTERNS, CRITICAL_EVENT_KEYWORDS
)
print('All classification imports OK')
"

# Tests pass
uv run python -m pytest tests/agents/sifters/classification/test_dubious_detector.py -v

# Boolean logic gate verification
uv run python -c "
from osint_system.agents.sifters.classification import DubiousDetector
from osint_system.data_management.schemas import DubiousFlag

detector = DubiousDetector()

# Verify Boolean gates (not weighted formulas)
# PHANTOM: hop_count > 2 AND primary_source IS NULL
phantom = {'provenance': {'hop_count': 3}}  # no primary
result = detector.detect(phantom, 0.7)
assert DubiousFlag.PHANTOM in result.flags

# FOG: claim_clarity < 0.5 OR vague attribution
fog = {'claim': {'text': 'x'}, 'quality': {'claim_clarity': 0.4}}
result = detector.detect(fog, 0.7)
assert DubiousFlag.FOG in result.flags

# NOISE: credibility < 0.3
result = detector.detect({'claim': {'text': 'x'}}, 0.2)
assert DubiousFlag.NOISE in result.flags

print('Boolean logic gates verified')
"
```
</verification>

<success_criteria>
- DubiousDetector uses Boolean logic gates (not weighted formulas)
- PHANTOM triggers on hop_count > 2 AND no primary source
- FOG triggers on claim_clarity < 0.5 OR vague attribution patterns
- ANOMALY triggers on contradiction_count > 0 (input from external)
- NOISE triggers on credibility < 0.3
- Classification prompts provide vague attribution patterns
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-fact-classification-system/07-03-SUMMARY.md`
</output>
