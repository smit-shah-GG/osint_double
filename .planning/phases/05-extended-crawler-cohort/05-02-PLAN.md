---
phase: 05-extended-crawler-cohort
plan: 02
type: execute
---

<objective>
Implement Reddit data collection with authority signals and message bus integration.

Purpose: Enable intelligent Reddit content collection with quality filtering and crawler coordination.
Output: Functional Reddit crawler that collects high-value content and integrates with the message bus.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-extended-crawler-cohort/05-CONTEXT.md
@.planning/phases/05-extended-crawler-cohort/05-RESEARCH.md
@.planning/phases/05-extended-crawler-cohort/05-01-SUMMARY.md
@osint_system/agents/crawlers/social_media_agent.py
@osint_system/agents/crawlers/newsfeed_agent.py
@osint_system/utils/message_bus.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement subreddit crawling with filters</name>
  <files>osint_system/agents/crawlers/social_media_agent.py</files>
  <action>Add crawl_investigation() method to RedditCrawler that accepts investigation_id and keywords. Implement search across multiple subreddits (news, worldnews, geopolitics by default). Add authority filtering: minimum score threshold (10), minimum comments (5), author verification check (not deleted/suspended). Follow comment chains for high-value posts (score > 100). Return structured data: posts list with content, metadata, and authority_score (0.3 for Reddit per RESEARCH.md). Use asyncpraw's search() with time filter "week" for recency.</action>
  <verify>grep "crawl_investigation" osint_system/agents/crawlers/social_media_agent.py shows method with filtering logic</verify>
  <done>crawl_investigation method implemented with authority filtering and comment following</done>
</task>

<task type="auto">
  <name>Task 2: Add message bus integration</name>
  <files>osint_system/agents/crawlers/social_media_agent.py</files>
  <action>Integrate RedditCrawler with MessageBus following Phase 4 patterns. Add __aenter__ and __aexit__ for async context manager. Subscribe to "reddit.crawl" topic in __aenter__. Implement handle_crawl_request() to process investigation messages. Publish results to "reddit.complete" with investigation_id, posts data, and metadata. Add error handling to publish "reddit.failed" on exceptions. Follow the pattern from newsfeed_agent.py for message structure.</action>
  <verify>grep -E "MessageBus|publish|subscribe" osint_system/agents/crawlers/social_media_agent.py shows integration</verify>
  <done>Message bus integration complete with publish/subscribe pattern</done>
</task>

<task type="auto">
  <name>Task 3: Create integration test</name>
  <files>tests/integration/test_reddit_crawler.py</files>
  <action>Create integration test for RedditCrawler. Test initialization with mock credentials, test crawl_investigation with sample keywords (skip if no real credentials), test message bus integration with mock investigation request, verify authority filtering works (low-score posts excluded), test error handling for API failures. Use pytest.mark.asyncio for async tests. Mock asyncpraw.Reddit if credentials not available.</action>
  <verify>uv run pytest tests/integration/test_reddit_crawler.py -v passes or skips gracefully</verify>
  <done>Integration tests created and passing/skipping appropriately</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] crawl_investigation method works with keywords
- [ ] Authority filtering excludes low-quality content
- [ ] Message bus integration functional
- [ ] Tests pass or skip gracefully
</verification>

<success_criteria>
- All tasks completed
- Reddit crawler filters by authority signals
- Message bus integration working
- Tests validate functionality
</success_criteria>

<output>
After completion, create `.planning/phases/05-extended-crawler-cohort/05-02-SUMMARY.md`:

# Phase 5 Plan 2: Reddit Data Collection Summary

**Reddit crawler now collects high-value content with authority filtering.**

## Accomplishments

- Implemented subreddit crawling with quality filters
- Added authority signals (score, comments, author verification)
- Integrated with message bus for coordination
- Created integration tests

## Files Created/Modified

- `osint_system/agents/crawlers/social_media_agent.py` - Added crawl_investigation and filtering
- `tests/integration/test_reddit_crawler.py` - Created integration tests

## Decisions Made

- Use score > 10 and comments > 5 as quality thresholds
- Follow comment threads for high-value posts (score > 100)
- Search recent content only (past week)
- Authority score of 0.3 for Reddit content

## Issues Encountered

[Any API limitations or authentication issues]

## Next Step

Ready for 05-03-PLAN.md - Document crawler implementation
</output>