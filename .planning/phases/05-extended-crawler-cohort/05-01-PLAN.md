---
phase: 05-extended-crawler-cohort
plan: 01
type: execute
---

<objective>
Set up Reddit crawler infrastructure with asyncpraw and async HTTP clients.

Purpose: Establish the foundation for Reddit data collection with proper authentication and rate limiting.
Output: Working RedditCrawler base class with asyncpraw integration and configuration.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-extended-crawler-cohort/05-CONTEXT.md
@.planning/phases/05-extended-crawler-cohort/05-RESEARCH.md
@.planning/phases/04-news-crawler/04-04-SUMMARY.md
@osint_system/agents/crawlers/base_crawler.py
@osint_system/agents/crawlers/social_media_agent.py
@osint_system/config/settings.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Reddit crawler dependencies</name>
  <files>requirements.txt</files>
  <action>Add the core Reddit crawler dependencies to requirements.txt: asyncpraw>=7.7.0, httpx>=0.25.0, aiometer>=0.5.0, yarl>=1.9.0, tenacity>=8.2.0. These provide async Reddit API access, fast HTTP client, rate limiting, URL handling, and retry logic. Use uv pip install -r requirements.txt to install after updating.</action>
  <verify>uv pip freeze | grep -E "asyncpraw|httpx|aiometer|yarl|tenacity" shows all packages installed</verify>
  <done>All 5 packages installed successfully, no import errors</done>
</task>

<task type="auto">
  <name>Task 2: Configure Reddit API authentication</name>
  <files>osint_system/config/settings.py, .env.example</files>
  <action>Add Reddit API configuration to settings.py: reddit_client_id, reddit_client_secret, reddit_user_agent (format: "osint_system:v0.1.0 (by /u/YourUsername)"). Add these fields to BaseSettings model with default empty strings. Update .env.example with placeholders: REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USER_AGENT. The user will need to create a Reddit app at https://www.reddit.com/prefs/apps to get credentials.</action>
  <verify>grep "reddit_" osint_system/config/settings.py shows 3 new config fields</verify>
  <done>Settings model has Reddit config fields, .env.example updated with placeholders</done>
</task>

<task type="auto">
  <name>Task 3: Implement RedditCrawler base class</name>
  <files>osint_system/agents/crawlers/social_media_agent.py</files>
  <action>Transform the skeleton SocialMediaAgent into RedditCrawler class. Import asyncpraw, httpx, aiometer. Create async Reddit client initialization in __init__. Add methods: _init_reddit_client() for asyncpraw.Reddit setup, fetch_subreddit() for getting posts from a subreddit with limit parameter, extract_post_data() to parse submission into structured format with title, text, url, score, author, created_utc, num_comments. Use async context manager pattern. Include error handling for API failures. Follow Pattern 2 from RESEARCH.md for rate limiting.</action>
  <verify>python -c "from osint_system.agents.crawlers.social_media_agent import RedditCrawler; print('Import successful')"</verify>
  <done>RedditCrawler class imports successfully, has required methods, inherits from BaseCrawler</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] All dependencies installed via uv
- [ ] Reddit API configuration in settings
- [ ] RedditCrawler class implemented
- [ ] No import errors
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No errors introduced
- Reddit crawler foundation established
</success_criteria>

<output>
After completion, create `.planning/phases/05-extended-crawler-cohort/05-01-SUMMARY.md`:

# Phase 5 Plan 1: Reddit Crawler Setup Summary

**Reddit crawler infrastructure established with asyncpraw and rate limiting.**

## Accomplishments

- Installed core dependencies (asyncpraw, httpx, aiometer, yarl, tenacity)
- Configured Reddit API authentication in settings
- Implemented RedditCrawler base class with async patterns

## Files Created/Modified

- `requirements.txt` - Added Reddit crawler dependencies
- `osint_system/config/settings.py` - Added Reddit API configuration
- `.env.example` - Added Reddit credential placeholders
- `osint_system/agents/crawlers/social_media_agent.py` - Implemented RedditCrawler

## Decisions Made

- Use asyncpraw for Reddit API access (async-first approach)
- Configure credentials via environment variables
- Follow aiometer rate limiting pattern from research

## Issues Encountered

[Any API auth issues or import problems]

## Next Step

Ready for 05-02-PLAN.md - Reddit data collection implementation
</output>