---
phase: 04-news-crawler
plan: 01
type: execute
---

<objective>
Implement the NewsFeedAgent base functionality with async architecture and rate limiting infrastructure.

Purpose: Establish the core crawler agent that can fetch news content on-demand with proper concurrency control.
Output: Working NewsFeedAgent with async patterns, rate limiting, and basic content extraction.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-news-crawler/04-CONTEXT.md
@.planning/phases/04-news-crawler/04-RESEARCH.md
@osint_system/agents/base_agent.py
@osint_system/agents/crawlers/base_crawler.py
@osint_system/communication/message_bus.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement NewsFeedAgent with async foundation</name>
  <files>osint_system/agents/crawlers/newsfeed_agent.py</files>
  <action>Create NewsFeedAgent class inheriting from BaseCrawler. Implement async fetch methods using httpx AsyncClient with proper context management. Include rate limiting infrastructure using token bucket pattern with semaphores for concurrent request control. Set default 10 req/sec limit with configurable per-source overrides. Use tenacity for retry logic with exponential backoff. Initialize agent with source configurations and investigation context support.</action>
  <verify>python -c "from osint_system.agents.crawlers.newsfeed_agent import NewsFeedAgent; agent = NewsFeedAgent(); print('Agent initialized')"</verify>
  <done>NewsFeedAgent class exists with async fetch methods and rate limiting</done>
</task>

<task type="auto">
  <name>Task 2: Add feedparser integration for RSS/Atom feeds</name>
  <files>osint_system/agents/crawlers/sources/rss_crawler.py</files>
  <action>Create RSSCrawler module with feedparser integration. Handle all RSS variants (0.91, 1.0, 2.0) and Atom feeds through feedparser's normalization. Extract title, link, published date, summary, author, and source metadata from entries. Handle encoding issues automatically through feedparser. Include fallback for malformed feeds with error logging. Parse and normalize dates using python-dateutil.</action>
  <verify>python -c "from osint_system.agents.crawlers.sources.rss_crawler import RSSCrawler; import asyncio; crawler = RSSCrawler(); print('RSS crawler ready')"</verify>
  <done>RSS crawler module exists and can parse feed formats</done>
</task>

<task type="auto">
  <name>Task 3: Integrate newspaper3k for article extraction</name>
  <files>osint_system/agents/crawlers/extractors/article_extractor.py</files>
  <action>Create ArticleExtractor using newspaper3k. Implement async wrapper around newspaper Article class for full text extraction. Extract text, top image, authors, keywords, and metadata. Handle JavaScript-heavy sites gracefully with fallback to RSS summary when extraction fails. Use language detection (langdetect) to filter non-English content. Cache extracted articles to avoid re-processing.</action>
  <verify>python -c "from osint_system.agents.crawlers.extractors.article_extractor import ArticleExtractor; extractor = ArticleExtractor(); print('Extractor initialized')"</verify>
  <done>Article extractor with newspaper3k integration complete</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -m pytest tests/agents/crawlers/test_newsfeed_agent.py -v` passes
- [ ] NewsFeedAgent can fetch from at least one test RSS feed
- [ ] Rate limiting prevents exceeding configured limits
- [ ] Article extraction produces clean text from URLs
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No import errors
- Async architecture established
- Rate limiting functional
</success_criteria>

<output>
After completion, create `.planning/phases/04-news-crawler/04-01-SUMMARY.md`:

# Phase 4 Plan 1: NewsFeedAgent Base Functionality Summary

**Established async news crawler with feedparser RSS integration and newspaper3k article extraction**

## Accomplishments

- Async NewsFeedAgent with httpx client
- Token bucket rate limiting with semaphores
- RSS/Atom parsing via feedparser
- Article extraction via newspaper3k
- Language detection and filtering

## Files Created/Modified

- `osint_system/agents/crawlers/newsfeed_agent.py` - Core agent implementation
- `osint_system/agents/crawlers/sources/rss_crawler.py` - RSS feed handler
- `osint_system/agents/crawlers/extractors/article_extractor.py` - Article text extraction

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for 04-02-PLAN.md (News API integration)
</output>