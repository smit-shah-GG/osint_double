---
phase: 08-verification-loop
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - osint_system/agents/sifters/verification/query_generator.py
  - osint_system/agents/sifters/verification/__init__.py
  - tests/agents/sifters/verification/test_query_generator.py
autonomous: true

must_haves:
  truths:
    - "PHANTOM facts get source-chain queries that trace back to root source"
    - "FOG facts get clarity-seeking queries for harder/clearer claims"
    - "ANOMALY facts get compound queries combining temporal + authority + clarity"
    - "Each fact gets up to 3 query variants before abandonment"
    - "NOISE-only facts are skipped (batch analysis only)"
  artifacts:
    - path: "osint_system/agents/sifters/verification/query_generator.py"
      provides: "Species-specialized query generation"
      exports: ["QueryGenerator"]
      min_lines: 200
    - path: "tests/agents/sifters/verification/test_query_generator.py"
      provides: "Query generation tests"
      min_lines: 150
  key_links:
    - from: "osint_system/agents/sifters/verification/query_generator.py"
      to: "osint_system/agents/sifters/verification/schemas.py"
      via: "VerificationQuery schema"
      pattern: "from.*schemas.*import.*VerificationQuery"
    - from: "osint_system/agents/sifters/verification/query_generator.py"
      to: "osint_system/data_management/schemas/classification_schema.py"
      via: "DubiousFlag enum"
      pattern: "from.*classification_schema.*import.*DubiousFlag"
---

<objective>
Implement species-specialized query generation for verification searches.

Purpose: Generate targeted search queries based on dubious flag type (PHANTOM/FOG/ANOMALY). Each species has a different verification strategy per CONTEXT.md: source-chain for PHANTOM, clarity-seeking for FOG, compound approach for ANOMALY.

Output: QueryGenerator class producing up to 3 query variants per fact, with species-specialized strategies that directly attack the specific type of doubt.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-verification-loop/08-CONTEXT.md
@.planning/phases/08-verification-loop/08-RESEARCH.md
@.planning/phases/08-verification-loop/08-01-SUMMARY.md
@osint_system/data_management/schemas/classification_schema.py
@osint_system/data_management/schemas/fact_schema.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement QueryGenerator with PHANTOM queries</name>
  <files>
    osint_system/agents/sifters/verification/query_generator.py
  </files>
  <action>
Create QueryGenerator class with PHANTOM query generation.

**QueryGenerator class:**

```python
class QueryGenerator:
    """Species-specialized query generation per CONTEXT.md decisions.

    Generates up to 3 query variants per fact based on dubious flag type.
    Each species has different verification strategy:
    - PHANTOM: Source-chain queries (trace back to root source)
    - FOG: Clarity-seeking queries (find harder/clearer claims)
    - ANOMALY: Compound queries (temporal + authority + clarity)
    - NOISE: Skipped (batch analysis only)
    """
```

**Constructor:**
- `max_queries: int = 3` - Maximum queries per fact per CONTEXT.md
- `logger` - structlog logger bound to "QueryGenerator"

**Core method:**
```python
async def generate_queries(
    self,
    fact: Dict[str, Any],
    classification: FactClassification,
) -> List[VerificationQuery]:
    """Generate up to 3 query variants per dubious flag.

    Returns empty list if:
    - No dubious flags
    - Only NOISE flag (batch analysis only)
    """
```

**PHANTOM queries (_generate_phantom_queries):**
Per CONTEXT.md: "Extract vague attribution, search for explicit versions. Prioritize wire services and official statements."

Generate 3 query variants:
1. **entity_focused**: `"{entity1} {entity2} official statement press release"`
   - Searches for named sources mentioning key entities
   - target_sources: ["wire_service", "official_statement"]
   - purpose: "Find named sources for entities mentioned in claim"

2. **exact_phrase**: `'"{claim_text[:100]}"'` (quoted exact phrase)
   - Searches for exact text to find original report
   - target_sources: ["news_outlet"]
   - purpose: "Find original publication of this specific claim"

3. **broader_context**: `"{entity1} {entity2} transcript interview statement"`
   - Searches for interviews/statements that might contain the claim
   - target_sources: ["official_statement", "wire_service"]
   - purpose: "Find primary source interview or statement"

Extract entities from `fact.get("entities", [])` - use canonical name if available, else text.
Extract attribution phrase from `fact.get("provenance", {}).get("attribution_phrase", "")`.
  </action>
  <verify>
`uv run python -c "from osint_system.agents.sifters.verification.query_generator import QueryGenerator; g = QueryGenerator(); print('QueryGenerator imported')"` succeeds
  </verify>
  <done>
QueryGenerator class exists with _generate_phantom_queries producing 3 query variants targeting source attribution
  </done>
</task>

<task type="auto">
  <name>Task 2: Add FOG and ANOMALY query strategies</name>
  <files>
    osint_system/agents/sifters/verification/query_generator.py
  </files>
  <action>
Extend QueryGenerator with FOG and ANOMALY query generation methods.

**FOG queries (_generate_fog_queries):**
Per CONTEXT.md: "Find harder/clearer version of claim"

The FOG problem is vague/unclear claims. Verification seeks more precise versions.

Generate 3 query variants:
1. **entity_focused**: `"{entity1} {entity2} confirmed report official"`
   - Looks for confirmed/official versions
   - target_sources: ["wire_service", "official_statement"]
   - purpose: "Find confirmed version of vague claim"

2. **clarity_enhancement**: Search for specific numbers/dates if claim has vague quantities
   - If claim contains "dozens", "many", "several", "some": `"{entities} exact number confirmed figure"`
   - If claim has vague temporal ("recently", "soon"): `"{entities} date confirmed when"`
   - Otherwise: `'"{claim_text[:80]}" site:reuters.com OR site:apnews.com'`
   - target_sources: ["wire_service"]
   - purpose: "Find more precise/quantified version"

3. **exact_phrase**: `'"{distinctive_phrase_from_claim}"'`
   - Find where this specific wording originated
   - target_sources: ["news_outlet"]
   - purpose: "Trace origin of specific claim language"

**ANOMALY queries (_generate_anomaly_queries):**
Per CONTEXT.md: "Compound approach - temporal + authority + clarity together, not sequential"

ANOMALY facts have contradictions. Verification must arbitrate between conflicting claims.

Get contradiction details from classification.get_flag_reasoning(DubiousFlag.ANOMALY).trigger_values.get("contradicting_fact_ids", [])

Generate 3 query variants:
1. **temporal_context**: Find dated/timestamped versions
   - If fact has temporal value: `"{entities} {temporal_value} timeline chronology"`
   - Else: `"{entities} latest update current status"`
   - target_sources: ["wire_service", "news_outlet"]
   - purpose: "Find dated versions to resolve if this is temporal progression"

2. **authority_arbitration**: Find higher-authority sources
   - `"{entities} official statement press release .gov"`
   - target_sources: ["official_statement", "wire_service"]
   - purpose: "Find higher-authority source to settle dispute"

3. **clarity_enhancement**: Find more specific versions
   - Check if claim text contains vague terms ("dozens", "many", etc.)
   - If vague: `"{entities} exact number confirmed figure"`
   - If specific: `'"{claim_text[:80]}" site:reuters.com OR site:apnews.com'`
   - target_sources: ["wire_service"]
   - purpose: "Find more precise version to resolve ambiguity"

**Update generate_queries():**
- Loop through classification.dubious_flags
- Call appropriate generator for each flag (skip NOISE)
- Limit total to max_queries (3)
- Log which flags produced which queries
  </action>
  <verify>
`uv run python -c "
from osint_system.agents.sifters.verification.query_generator import QueryGenerator
from osint_system.data_management.schemas import DubiousFlag, FactClassification
import asyncio

g = QueryGenerator()
# Test with FOG flag
fog_class = FactClassification(fact_id='test', investigation_id='inv', dubious_flags=[DubiousFlag.FOG])
fact = {'fact_id': 'test', 'claim': {'text': 'Several officials said'}, 'entities': [{'text': 'Russia'}]}
queries = asyncio.run(g.generate_queries(fact, fog_class))
print(f'FOG queries: {len(queries)}')
assert len(queries) <= 3
"` succeeds
  </verify>
  <done>
FOG queries target clarity (finding more precise versions), ANOMALY queries use compound approach (temporal + authority + clarity)
  </done>
</task>

<task type="auto">
  <name>Task 3: Add comprehensive tests and export</name>
  <files>
    tests/agents/sifters/verification/test_query_generator.py
    osint_system/agents/sifters/verification/__init__.py
  </files>
  <action>
Create comprehensive tests for QueryGenerator and update exports.

**test_query_generator.py:**

Test categories (pytest, use async tests with pytest-asyncio):

1. **Initialization tests:**
   - Default max_queries is 3
   - Custom max_queries accepted
   - Logger is bound

2. **PHANTOM query tests:**
   - Generates 3 queries for PHANTOM flag
   - Queries include entity names from fact
   - entity_focused targets wire_service
   - exact_phrase uses quoted claim text
   - broader_context searches for transcripts
   - Handles facts with no entities gracefully

3. **FOG query tests:**
   - Generates 3 queries for FOG flag
   - Detects vague quantities ("dozens", "many", "several")
   - clarity_enhancement queries target specifics
   - Handles claims without vague language

4. **ANOMALY query tests:**
   - Generates 3 queries for ANOMALY flag
   - temporal_context uses temporal value if present
   - authority_arbitration targets .gov and wire services
   - Handles claims without temporal info

5. **Edge case tests:**
   - Empty dubious_flags returns empty list
   - NOISE-only returns empty list (batch analysis only)
   - Multi-flag (PHANTOM + FOG) returns max 3 queries total
   - Missing entities handled gracefully
   - Missing claim text handled gracefully

6. **Query variant type tests:**
   - All queries have valid variant_type
   - All queries have purpose set
   - All queries have dubious_flag set
   - target_sources is non-empty

Use fixtures:
- `@pytest.fixture` for sample facts with different structures
- `@pytest.fixture` for classifications with different flags

**Update __init__.py:**
Export QueryGenerator alongside schemas.

Target: 25+ tests covering all query strategies and edge cases.
  </action>
  <verify>
`uv run python -m pytest tests/agents/sifters/verification/test_query_generator.py -v` passes with 25+ tests
  </verify>
  <done>
All query generation tests pass, coverage includes all 3 species strategies, edge cases, and variant type validation
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "from osint_system.agents.sifters.verification import QueryGenerator"` succeeds
2. `uv run python -m pytest tests/agents/sifters/verification/test_query_generator.py -v` all tests pass
3. PHANTOM queries target source attribution (entity_focused, exact_phrase, broader_context)
4. FOG queries target clarity (vague term detection, precise version seeking)
5. ANOMALY queries use compound approach (temporal, authority, clarity)
6. NOISE-only facts return empty query list
</verification>

<success_criteria>
- QueryGenerator.generate_queries() returns up to 3 queries per fact
- PHANTOM strategy: source-chain queries targeting root source attribution
- FOG strategy: clarity-seeking queries for more precise claim versions
- ANOMALY strategy: compound queries (temporal + authority + clarity together)
- NOISE-only facts return empty list (excluded from individual verification)
- Multi-flag facts (e.g., PHANTOM + FOG) still limited to 3 queries total
- 25+ tests pass covering all strategies and edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/08-verification-loop/08-02-SUMMARY.md`
</output>
